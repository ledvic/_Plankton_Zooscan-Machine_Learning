{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "\n",
    "from random import sample\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "import skimage\n",
    "from skimage import io\n",
    "from skimage.feature import daisy, hog, ORB, local_binary_pattern, SIFT\n",
    "from skimage.color import label2rgb, rgb2gray\n",
    "from skimage.transform import resize, rotate, downscale_local_mean\n",
    "\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.util import img_as_float\n",
    "from skimage.filters import gabor_kernel\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from skimage import exposure\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gc\n",
    "\n",
    "from joblib import Parallel, delayed, parallel_backend, cpu_count\n",
    "import psutil\n",
    "\n",
    "from platform import python_version\n",
    "\n",
    "\n",
    "import gabor_filters\n",
    "from  gabor_filters import gabor_filter\n",
    "from  gabor_filters import gabor_filter_response\n",
    "\n",
    "import importlib\n",
    "importlib.reload(gabor_filters)\n",
    "importlib.reload(gabor_filters.gabor_filter)\n",
    "importlib.reload(gabor_filters.gabor_filter_response)\n",
    "\n",
    "from gabor_filters.gabor_filter import GaborFilterBank as gbb\n",
    "from gabor_filters.gabor_filter_response import GaborFilteredResponseBank as gbfrb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.16\n",
      "0.19.2\n"
     ]
    }
   ],
   "source": [
    "print(python_version())\n",
    "print(skimage.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_gabor_from_filepath(filepath):\n",
    "    # read image from its path\n",
    "    img = io.imread(filepath, as_gray=True)\n",
    "    \n",
    "    # Create Gabor filter bank\n",
    "    fmax = 0.327 # maximum frequency\n",
    "    k = np.sqrt(2) #frequency ratio or factor for selecting filter frequencies\n",
    "    p = 0.5 # crossing point between two consecutive filters, default 0.5\n",
    "    u = 6 #number of frequencies\n",
    "    v = 8 #number of orientation\n",
    "    gamma = 0.5  #smoothting parameter \n",
    "    eta = 0.5  #smoothting parameter of\n",
    "    row = img.shape[0]\n",
    "    col = img.shape[1] # size of image\n",
    "\n",
    "    GaborFilterBank = gbb().create_a_set_of_gabor_filters(fmax, k, p, u, v, row, col, gamma, eta)\n",
    "    \n",
    "    # Filter with the filter bank\n",
    "    GaborFilteredReponses = gbfrb().create_a_set_of_Gabor_filtered_responses(img, GaborFilterBank)\n",
    "\n",
    "    # Convert responses to simple 3-D matrix with normalization\n",
    "    filteredImages = gbfrb().convert_a_set_Gabor_filtered_responses_to_ndarray(GaborFilteredReponses)\n",
    "    \n",
    "    # Get mean and standard deviation of each response as Gabor (texture) features of an input image\n",
    "    nImages = filteredImages.shape[2]\n",
    "    textureFeatures = np.zeros(nImages*2)\n",
    "\n",
    "    index=0\n",
    "    for i in range(0, nImages):\n",
    "        textureFeatures[index] = np.mean(np.abs(filteredImages[:,:,i]));\n",
    "        index = index + 1;\n",
    "        textureFeatures[index] = np.std(np.abs(filteredImages[:,:,i]));\n",
    "        index = index + 1;\n",
    "    \n",
    "    return textureFeatures\n",
    "\n",
    "# def extract_gabor(dfDataset):\n",
    "#     # chunk the large dataset int smaller pieces\n",
    "#     n = 1000\n",
    "#     list_dfDataset_chunk = [dfDataset[i:i+n] for i in range(0, len(dfDataset), n)]\n",
    "    \n",
    "#     gabor_list = [None]*len(list_dfDataset_chunk)\n",
    "\n",
    "#     with parallel_backend(\"loky\", inner_max_num_threads=2):\n",
    "#         with Parallel(n_jobs=10, require='sharedmem') as parallel:\n",
    "#             for i, dfDataset_chunk in enumerate(tqdm(list_dfDataset_chunk, desc='Processing data', colour='blue', position=0, leave=True)):\n",
    "            \n",
    "#                 gabor_features = parallel(\n",
    "#                                 delayed(extract_gabor_from_filepath)(filepath) for filepath in tqdm(dfDataset_chunk['filenames'], desc='Extract Gabor', colour='cyan', position=1, leave=False)\n",
    "#                             )\n",
    "            \n",
    "#                 gabor_list[i] = gabor_features\n",
    "\n",
    "#                 del  gabor_features\n",
    "#                 gc.collect()\n",
    "    \n",
    "#     return gabor_list\n",
    "\n",
    "\n",
    "# def extract_gabor_2(dfDataset):\n",
    "    \n",
    "#     # with parallel_backend(\"loky\", inner_max_num_threads=3):\n",
    "#     with Parallel(n_jobs=30, require='sharedmem', return_generator=True) as parallel:\n",
    "        \n",
    "#         gabor_features = parallel(\n",
    "#                         delayed(extract_gabor_from_filepath)(filepath) for filepath in tqdm(dfDataset['filenames'], desc='Extract Gabor', colour='cyan')\n",
    "#                     )\n",
    "            \n",
    "#     return gabor_features\n",
    "\n",
    "\n",
    "# def extract_gabor_3(dfDataset):\n",
    "#     with Parallel(n_jobs=20, max_nbytes=100e6) as parallel:\n",
    "        \n",
    "#         gabor_features = parallel(\n",
    "#                         delayed(extract_gabor_from_filepath)(filepath) for filepath in tqdm(dfDataset['filenames'], desc='Extract Gabor', colour='cyan')\n",
    "#                     )\n",
    "            \n",
    "#     return gabor_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_gabor_from_filepaths(filepaths):\n",
    "#     # Create ndarray of zeros to hold results\n",
    "#     n_filepaths = len(filepaths)\n",
    "#     n_features = 96\n",
    "#     textureFeatures_array = np.zeros((n_filepaths, n_features))\n",
    "    \n",
    "#     # Fill in results using Parallel\n",
    "#     for i, textureFeatures in enumerate(Parallel(n_jobs=20, backend='loky')(delayed(extract_gabor_from_filepath)(filepath) for filepath in tqdm(filepaths['filenames'], desc='Extract Gabor', colour='cyan'))):\n",
    "#         textureFeatures_array[i] = textureFeatures\n",
    "    \n",
    "#     return textureFeatures_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_file(filepath):\n",
    "#     # call your function to extract texture features from file\n",
    "#     texture_features = extract_gabor_from_filepath(filepath)\n",
    "#     return texture_features\n",
    "\n",
    "# def process_files(filepaths):\n",
    "#     with ThreadPoolExecutor() as executor:\n",
    "#         results = executor.map(process_file, filepaths)\n",
    "#     return list(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_file_batch(filepaths):\n",
    "#     # results = []\n",
    "\n",
    "#     # Create ndarray of zeros to hold results\n",
    "#     n_filepaths = len(filepaths)\n",
    "#     n_features = 96\n",
    "#     results = np.zeros((n_filepaths, n_features))\n",
    "\n",
    "#     for i, filepath in enumerate(filepaths):\n",
    "#         # call your function to extract texture features from file\n",
    "#         results[i] = extract_gabor_from_filepath(filepath)\n",
    "#         # results.append(texture_features)\n",
    "#     return results\n",
    "\n",
    "# def process_files(filepaths, batch_size=10, n_jobs=-10):\n",
    "#     n_files = len(filepaths)\n",
    "#     batch_indices = np.arange(0, n_files, batch_size)\n",
    "#     if batch_indices[-1] != n_files:\n",
    "#         batch_indices = np.concatenate([batch_indices, [n_files]])\n",
    "#     results = []\n",
    "#     with tqdm(total=n_files) as pbar:\n",
    "#         for i in range(len(batch_indices) - 1):\n",
    "#             batch_filepaths = filepaths[batch_indices[i]:batch_indices[i+1]]\n",
    "#             batch_results = Parallel(n_jobs=n_jobs)(\n",
    "#                 delayed(process_file_batch)(batch_filepaths) for filepath in batch_filepaths)\n",
    "#             results.extend(batch_results)\n",
    "#             pbar.update(len(batch_filepaths))\n",
    "#     return results\n",
    "\n",
    "\n",
    "# def process_files2(filepaths, batch_size=10, n_jobs=-1):\n",
    "#     n_files = len(filepaths)\n",
    "#     batch_indices = np.arange(0, n_files, batch_size)\n",
    "#     if batch_indices[-1] != n_files:\n",
    "#         batch_indices = np.concatenate([batch_indices, [n_files]])\n",
    "#     results = []\n",
    "#     with tqdm(total=n_files) as pbar:\n",
    "#         for i in range(len(batch_indices) - 1):\n",
    "#             batch_filepaths = filepaths[batch_indices[i]:batch_indices[i+1]]\n",
    "#             batch_results = Parallel(n_jobs=n_jobs)(\n",
    "#                 delayed(process_file_batch)(batch_filepaths))\n",
    "#             for batch_result in batch_results:\n",
    "#                 results.extend(batch_result)\n",
    "#             pbar.update(len(batch_filepaths))\n",
    "#     return results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. main()\n",
    "\n",
    "### 4.2.1. For fold 1\n",
    "#### 1. Read path of fold 1 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFoldTraining_1 = pd.read_csv('..//_inputs//_images_Zooscan//_Zooscan-training-fold_1.csv')\n",
    "dfFoldValidation_1 = pd.read_csv('..//_inputs//_images_Zooscan//_Zooscan-validation-fold_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filenames</th>\n",
       "      <th>labels</th>\n",
       "      <th>short_filenames</th>\n",
       "      <th>cls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>..//_inputs//_images_Zooscan//_training//aggre...</td>\n",
       "      <td>aggregats_debris</td>\n",
       "      <td>0001-aggregates.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>..//_inputs//_images_Zooscan//_training//aggre...</td>\n",
       "      <td>aggregats_debris</td>\n",
       "      <td>0002.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>..//_inputs//_images_Zooscan//_training//aggre...</td>\n",
       "      <td>aggregats_debris</td>\n",
       "      <td>0003-aggregates.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>..//_inputs//_images_Zooscan//_training//aggre...</td>\n",
       "      <td>aggregats_debris</td>\n",
       "      <td>0004-aggregates.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>..//_inputs//_images_Zooscan//_training//aggre...</td>\n",
       "      <td>aggregats_debris</td>\n",
       "      <td>0004.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           filenames            labels  \\\n",
       "0  ..//_inputs//_images_Zooscan//_training//aggre...  aggregats_debris   \n",
       "1  ..//_inputs//_images_Zooscan//_training//aggre...  aggregats_debris   \n",
       "2  ..//_inputs//_images_Zooscan//_training//aggre...  aggregats_debris   \n",
       "3  ..//_inputs//_images_Zooscan//_training//aggre...  aggregats_debris   \n",
       "4  ..//_inputs//_images_Zooscan//_training//aggre...  aggregats_debris   \n",
       "\n",
       "       short_filenames  cls  \n",
       "0  0001-aggregates.png    0  \n",
       "1             0002.png    0  \n",
       "2  0003-aggregates.png    0  \n",
       "3  0004-aggregates.png    0  \n",
       "4             0004.png    0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(44099, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dfFoldTraining_1.head(5), dfFoldTraining_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count=0\n",
    "for i, filepath in enumerate(dfFoldTraining_1['filenames']):\n",
    "    img = io.imread(filepath, as_gray=True)\n",
    "\n",
    "    img_height = img.shape[0]\n",
    "\n",
    "    if img_height > 2000:\n",
    "        # print(i, filepath)\n",
    "        count +=1\n",
    "\n",
    "display(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filepath in dfFoldTraining_1['filenames'][3550:3550+34]:\n",
    "    print(filepath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Extracting gabor feature for the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files(filepaths, batch_size=100, n_jobs=-1):\n",
    "    print(\"Iteration before chunking dataset: %0.3f MB\" % (\n",
    "                                        psutil.Process().memory_info().rss / 1e6))\n",
    "    n_files = len(filepaths)\n",
    "    batch_indices = np.arange(0, n_files, batch_size)\n",
    "    if batch_indices[-1] != n_files:\n",
    "        batch_indices = np.concatenate([batch_indices, [n_files]])\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    with tqdm(total=n_files) as pbar:\n",
    "        with Parallel(n_jobs=n_jobs, max_nbytes=1000e6) as parallel:\n",
    "            for i in range(len(batch_indices) - 1):\n",
    "                gc.collect()\n",
    "                batch_filepaths = filepaths[batch_indices[i]:batch_indices[i+1]]\n",
    "\n",
    "                print(\"Iteration %d: %0.3f MB\" % (\n",
    "                                        i, psutil.Process().memory_info().rss / 1e6))\n",
    "                batch_results = parallel(\n",
    "                                delayed(extract_gabor_from_filepath)(filepath) for filepath in batch_filepaths\n",
    "                            )\n",
    "            \n",
    "                for batch_result in batch_results:\n",
    "                    results.extend(batch_result)\n",
    "\n",
    "                print(\"Iteration %d after extending output: %0.3f MB\" % (i, psutil.Process().memory_info().rss / 1e6))\n",
    "                pbar.update(len(batch_filepaths))\n",
    "  \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texture_features = process_files(dfFoldTraining_1['filenames'], batch_size=200, n_jobs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_gabor_from_filepath(img):    \n",
    "    # Create Gabor filter bank\n",
    "    fmax = 0.327 # maximum frequency\n",
    "    k = np.sqrt(2) #frequency ratio or factor for selecting filter frequencies\n",
    "    p = 0.5 # crossing point between two consecutive filters, default 0.5\n",
    "    u = 6 #number of frequencies\n",
    "    v = 8 #number of orientation\n",
    "    gamma = 0.5  #smoothting parameter \n",
    "    eta = 0.5  #smoothting parameter of\n",
    "    row = img.shape[0]\n",
    "    col = img.shape[1] # size of image\n",
    "\n",
    "    GaborFilterBank = gbb().create_a_set_of_gabor_filters(fmax, k, p, u, v, row, col, gamma, eta)\n",
    "    \n",
    "    # Filter with the filter bank\n",
    "    GaborFilteredReponses = gbfrb().create_a_set_of_Gabor_filtered_responses(img, GaborFilterBank)\n",
    "\n",
    "    # Convert responses to simple 3-D matrix with normalization\n",
    "    filteredImages = gbfrb().convert_a_set_Gabor_filtered_responses_to_ndarray(GaborFilteredReponses)\n",
    "    \n",
    "    # Get mean and standard deviation of each response as Gabor (texture) features of an input image\n",
    "    nImages = filteredImages.shape[2]\n",
    "    textureFeatures = np.zeros(nImages*2)\n",
    "\n",
    "    index=0\n",
    "    for i in range(0, nImages):\n",
    "        textureFeatures[index] = np.mean(np.abs(filteredImages[:,:,i]));\n",
    "        index = index + 1;\n",
    "        textureFeatures[index] = np.std(np.abs(filteredImages[:,:,i]));\n",
    "        index = index + 1;\n",
    "    \n",
    "    return textureFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import threshold_niblack\n",
    "from skimage.morphology import convex_hull_image\n",
    "from skimage.measure import find_contours\n",
    "\n",
    "def crop_image(image):\n",
    "    img_height = image.shape[0]\n",
    "    if img_height < 2000:\n",
    "        return image\n",
    "    \n",
    "    # adaptive thresholding\n",
    "    thresh_niblack = threshold_niblack(image, window_size=25, k=0.8)\n",
    "    binary_niblack = image > thresh_niblack\n",
    "\n",
    "    # make convex hull\n",
    "    chull = convex_hull_image(np.pad(binary_niblack, 3, 'constant', constant_values=0))\n",
    "    \n",
    "    # Find the contours of the main object\n",
    "    contours = find_contours(chull, 0.5)\n",
    "\n",
    "    # Find the largest contour (assumed to be the main object)\n",
    "    largest_contour = max(contours, key=len)\n",
    "\n",
    "    # Compute the bounding box coordinates for the largest contour\n",
    "    min_row, min_col = np.min(largest_contour, axis=0)\n",
    "    max_row, max_col = np.max(largest_contour, axis=0)\n",
    "\n",
    "    # Compute the optimal cropping dimensions based on the bounding box\n",
    "    padding = 10  # Adjust the padding as desired\n",
    "    crop_min_row = int(max(min_row - padding, 0))\n",
    "    crop_min_col = int(max(min_col - padding, 0))\n",
    "    crop_max_row = int(min(max_row + padding, image.shape[0]))\n",
    "    crop_max_col = int(min(max_col + padding, image.shape[1]))\n",
    "\n",
    "    # Crop the image using the computed dimensions\n",
    "    cropped_image = image[crop_min_row:crop_max_row, crop_min_col:crop_max_col]\n",
    "\n",
    "    return cropped_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "from more_itertools import chunked\n",
    "\n",
    "\n",
    "\n",
    "def image_generator(filepaths):\n",
    "    for filepath in filepaths:\n",
    "        yield io.imread(filepath, as_gray=True)\n",
    "\n",
    "def extract_texture_features(img):\n",
    "    img = crop_image(img)\n",
    "    textureFeatures = extract_gabor_from_filepath(img)\n",
    "    return textureFeatures\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = dfFoldTraining_1['filenames']\n",
    "batch_size = 100\n",
    "num_processes = mp.cpu_count()-10\n",
    "with mp.Pool(processes=num_processes) as pool:\n",
    "    results = []\n",
    "    for batch in tqdm(chunked(image_generator(filepaths), batch_size), total=len(filepaths)//batch_size):\n",
    "        batch_results = list(pool.imap(extract_texture_features, batch, chunksize=1))\n",
    "        results.extend(batch_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = dfFoldTraining_1['filenames']\n",
    "batch_size = 100\n",
    "chunk_size = 400\n",
    "num_processes = mp.cpu_count()-10\n",
    "with mp.Pool(processes=num_processes) as pool:\n",
    "    results = []\n",
    "    for batch in tqdm(chunked(image_generator(filepaths), batch_size), total=len(filepaths)//batch_size):\n",
    "        batch_results = list(pool.imap(extract_texture_features, batch, chunksize=chunk_size))\n",
    "        results.extend(batch_results)\n",
    "    pool.close()\n",
    "    pool.join()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Test with multiprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "from more_itertools import chunked\n",
    "\n",
    "from skimage.filters import threshold_niblack\n",
    "from skimage.morphology import convex_hull_image\n",
    "from skimage.measure import find_contours\n",
    "\n",
    "def image_generator(filepaths):\n",
    "    for filepath in filepaths:\n",
    "        yield io.imread(filepath, as_gray=True)\n",
    "\n",
    "def extract_texture_features(image): \n",
    "\n",
    "    img = crop_image(image)\n",
    "\n",
    "    # Create Gabor filter bank\n",
    "    fmax = 0.327 # maximum frequency\n",
    "    k = np.sqrt(2) #frequency ratio or factor for selecting filter frequencies\n",
    "    p = 0.5 # crossing point between two consecutive filters, default 0.5\n",
    "    u = 6 #number of frequencies\n",
    "    v = 8 #number of orientation\n",
    "    gamma = 0.5  #smoothting parameter \n",
    "    eta = 0.5  #smoothting parameter of\n",
    "    row = img.shape[0]\n",
    "    col = img.shape[1] # size of image\n",
    "\n",
    "    GaborFilterBank = gbb().create_a_set_of_gabor_filters(fmax, k, p, u, v, row, col, gamma, eta)\n",
    "    \n",
    "    # Filter with the filter bank\n",
    "    GaborFilteredReponses = gbfrb().create_a_set_of_Gabor_filtered_responses(img, GaborFilterBank)\n",
    "\n",
    "    # Convert responses to simple 3-D matrix with normalization\n",
    "    filteredImages = gbfrb().convert_a_set_Gabor_filtered_responses_to_ndarray(GaborFilteredReponses)\n",
    "    \n",
    "    # Get mean and standard deviation of each response as Gabor (texture) features of an input image\n",
    "    nImages = filteredImages.shape[2]\n",
    "    textureFeatures = np.zeros(nImages*2)\n",
    "\n",
    "    index=0\n",
    "    for i in range(0, nImages):\n",
    "        textureFeatures[index] = np.mean(np.abs(filteredImages[:,:,i]));\n",
    "        index = index + 1;\n",
    "        textureFeatures[index] = np.std(np.abs(filteredImages[:,:,i]));\n",
    "        index = index + 1;\n",
    "    \n",
    "    return textureFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7e4c89e18aa4ba8a64dca805e317940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extract Gabor features:   0%|          | 0/44099 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/image_processing/lib/python3.8/multiprocessing/pool.py:851\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    850\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 851\u001b[0m     item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_items\u001b[39m.\u001b[39;49mpopleft()\n\u001b[1;32m    852\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m:\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 24\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mwith\u001b[39;00m mp\u001b[39m.\u001b[39mPool(processes\u001b[39m=\u001b[39mnum_processes) \u001b[39mas\u001b[39;00m pool:\n\u001b[1;32m     22\u001b[0m     \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m chunked(image_generator(filepaths), batch_size):\n\u001b[0;32m---> 24\u001b[0m         batch_results \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(pool\u001b[39m.\u001b[39;49mimap(extract_texture_features, batch, chunksize\u001b[39m=\u001b[39;49mchunk_size))\n\u001b[1;32m     26\u001b[0m         results\u001b[39m.\u001b[39mextend(batch_results)\n\u001b[1;32m     28\u001b[0m         \u001b[39mdel\u001b[39;00m batch_results\n",
      "File \u001b[0;32m~/anaconda3/envs/image_processing/lib/python3.8/multiprocessing/pool.py:420\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    412\u001b[0m result \u001b[39m=\u001b[39m IMapIterator(\u001b[39mself\u001b[39m)\n\u001b[1;32m    413\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_taskqueue\u001b[39m.\u001b[39mput(\n\u001b[1;32m    414\u001b[0m     (\n\u001b[1;32m    415\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_guarded_task_generation(result\u001b[39m.\u001b[39m_job,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    418\u001b[0m         result\u001b[39m.\u001b[39m_set_length\n\u001b[1;32m    419\u001b[0m     ))\n\u001b[0;32m--> 420\u001b[0m \u001b[39mreturn\u001b[39;00m (item \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m result \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m chunk)\n",
      "File \u001b[0;32m~/anaconda3/envs/image_processing/lib/python3.8/multiprocessing/pool.py:856\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    854\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pool \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    855\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m--> 856\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    857\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    858\u001b[0m     item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_items\u001b[39m.\u001b[39mpopleft()\n",
      "File \u001b[0;32m~/anaconda3/envs/image_processing/lib/python3.8/threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    303\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "filepaths = dfFoldTraining_1['filenames']\n",
    "\n",
    "n_files = len(filepaths)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "num_processes = 4\n",
    "\n",
    "results = []\n",
    "\n",
    "chunk_size = 64\n",
    "\n",
    "num_processes = mp.cpu_count() - 10 # number of workers\n",
    "\n",
    "i=0;\n",
    "with tqdm(total=n_files, desc=\"Extract Gabor features\") as pbar:\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    with mp.Pool(processes=num_processes) as pool:\n",
    "\n",
    "        for batch in chunked(image_generator(filepaths), batch_size):\n",
    "            \n",
    "            batch_results = list(pool.imap(extract_texture_features, batch, chunksize=chunk_size))\n",
    "            \n",
    "            results.extend(batch_results)\n",
    "\n",
    "            del batch_results\n",
    "\n",
    "            gc.collect()\n",
    "\n",
    "            pbar.update(len(batch))\n",
    "\n",
    "        # pool.close()\n",
    "        # pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3552, 96)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(results).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del results\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Test with joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "from more_itertools import chunked\n",
    "\n",
    "def image_generator(filepaths):\n",
    "    for filepath in filepaths:\n",
    "        yield io.imread(filepath, as_gray=True)\n",
    "\n",
    "def extract_texture_features(img):    \n",
    "    # Create Gabor filter bank\n",
    "    fmax = 0.327 # maximum frequency\n",
    "    k = np.sqrt(2) #frequency ratio or factor for selecting filter frequencies\n",
    "    p = 0.5 # crossing point between two consecutive filters, default 0.5\n",
    "    u = 6 #number of frequencies\n",
    "    v = 8 #number of orientation\n",
    "    gamma = 0.5  #smoothting parameter \n",
    "    eta = 0.5  #smoothting parameter of\n",
    "    row = img.shape[0]\n",
    "    col = img.shape[1] # size of image\n",
    "\n",
    "    GaborFilterBank = gbb().create_a_set_of_gabor_filters(fmax, k, p, u, v, row, col, gamma, eta)\n",
    "    \n",
    "    # Filter with the filter bank\n",
    "    GaborFilteredReponses = gbfrb().create_a_set_of_Gabor_filtered_responses(img, GaborFilterBank)\n",
    "\n",
    "    # Convert responses to simple 3-D matrix with normalization\n",
    "    filteredImages = gbfrb().convert_a_set_Gabor_filtered_responses_to_ndarray(GaborFilteredReponses)\n",
    "    \n",
    "    # Get mean and standard deviation of each response as Gabor (texture) features of an input image\n",
    "    nImages = filteredImages.shape[2]\n",
    "    textureFeatures = np.zeros(nImages*2)\n",
    "\n",
    "    index=0\n",
    "    for i in range(0, nImages):\n",
    "        textureFeatures[index] = np.mean(np.abs(filteredImages[:,:,i]));\n",
    "        index = index + 1;\n",
    "        textureFeatures[index] = np.std(np.abs(filteredImages[:,:,i]));\n",
    "        index = index + 1;\n",
    "    \n",
    "    return textureFeatures\n",
    "from more_itertools import chunked\n",
    "\n",
    "def image_generator(filepaths):\n",
    "    for filepath in filepaths:\n",
    "        yield io.imread(filepath, as_gray=True)\n",
    "\n",
    "def extract_texture_features(img):\n",
    "    \n",
    "    # Create Gabor filter bank\n",
    "    fmax = 0.327 # maximum frequency\n",
    "    k = np.sqrt(2) #frequency ratio or factor for selecting filter frequencies\n",
    "    p = 0.5 # crossing point between two consecutive filters, default 0.5\n",
    "    u = 6 #number of frequencies\n",
    "    v = 8 #number of orientation\n",
    "    gamma = 0.5  #smoothting parameter \n",
    "    eta = 0.5  #smoothting parameter of\n",
    "    row = img.shape[0]\n",
    "    col = img.shape[1] # size of image\n",
    "\n",
    "    GaborFilterBank = gbb().create_a_set_of_gabor_filters(fmax, k, p, u, v, row, col, gamma, eta)\n",
    "    \n",
    "    # Filter with the filter bank\n",
    "    GaborFilteredReponses = gbfrb().create_a_set_of_Gabor_filtered_responses(img, GaborFilterBank)\n",
    "\n",
    "    # Convert responses to simple 3-D matrix with normalization\n",
    "    filteredImages = gbfrb().convert_a_set_Gabor_filtered_responses_to_ndarray(GaborFilteredReponses)\n",
    "    \n",
    "    # Get mean and standard deviation of each response as Gabor (texture) features of an input image\n",
    "    nImages = filteredImages.shape[2]\n",
    "    textureFeatures = np.zeros(nImages*2)\n",
    "\n",
    "    index=0\n",
    "    for i in range(0, nImages):\n",
    "        textureFeatures[index] = np.mean(np.abs(filteredImages[:,:,i]));\n",
    "        index = index + 1;\n",
    "        textureFeatures[index] = np.std(np.abs(filteredImages[:,:,i]));\n",
    "        index = index + 1;\n",
    "    \n",
    "    return textureFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = dfFoldTraining_1['filenames'][3550:]\n",
    "\n",
    "n_files = len(filepaths)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "num_processes = 4\n",
    "\n",
    "results = []\n",
    "\n",
    "i=0;\n",
    "with tqdm(total=n_files, desc=\"Extract Gabor features\") as pbar:\n",
    "\n",
    "    with Parallel(n_jobs=num_processes) as parallel:\n",
    "\n",
    "        for batch in chunked(image_generator(filepaths), batch_size):\n",
    "            \n",
    "            i=i+1\n",
    "            print('Working with batch: ',i)\n",
    "\n",
    "            batch_results = parallel(\n",
    "                delayed(extract_texture_features)(img) for img in batch)\n",
    "            \n",
    "            results.extend(batch_results)\n",
    "\n",
    "            del batch_results\n",
    "            gc.collect()\n",
    "\n",
    "            pbar.update(len(batch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texture_features = process_files(dfFoldTraining_1['filenames'], batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texture_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_gabor_train = process_files(dfFoldTraining_1['filenames'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_gabor_train = extract_gabor_from_filepaths(dfFoldTraining_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_gabor_train2 = np.vstack(list_gabor_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_gabor_train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del list_gabor_train2, list_gabor_train\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2000\n",
    "\n",
    "list_dfFoldTraining_1_chunked = [dfFoldTraining_1[i:i+n] for i in range(0, len(dfFoldTraining_1), n)]\n",
    "\n",
    "display(len(list_dfFoldTraining_1_chunked))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Parallel(n_jobs=2) as parallel:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gabor_list_train = None\n",
    "\n",
    "pbar = tqdm(list_dfFoldTraining_1_chunked)\n",
    "\n",
    "for i, dfFoldTraining_1_chunked in enumerate(pbar):\n",
    "    pbar.set_description(f'Processing the chunked data {i+1}')\n",
    "    \n",
    "    gabor_list_train_chunked = extract_gabor(dfFoldTraining_1_chunked)\n",
    "\n",
    "    gabor_list_train = np.vstack(gabor_list_train_chunked)\n",
    "\n",
    "    del  gabor_list_train_chunked\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a standard deviation normalization for later uses\n",
    "train_std_norm = StandardScaler().fit(HOG_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard deviation normalization\n",
    "HOG_list_std = train_std_norm.transform(HOG_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HOG_list_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total HOG features:',(HOG_list_std.shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. PCA analysis on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_HOG_std = PCA().fit(HOG_list_std)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1. Plot PCA components and CEV\n",
    "\n",
    "From this, we can know number of components to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5), tight_layout=True)\n",
    "\n",
    "ax.plot(np.cumsum(pca_HOG_std.explained_variance_ratio_)*100, linewidth=2)\n",
    "ax.grid(color='r', linestyle='--', linewidth=1)\n",
    "\n",
    "ax.set_xlabel('Number of components')\n",
    "ax.set_ylabel('Cumulative explained variance');\n",
    "\n",
    "ax.set_yticks(np.arange(0,105,5))\n",
    "ax.set_xticks(np.arange(0,HOG_list.shape[1],100))\n",
    "\n",
    "ax.axhline(y=90, linewidth=3, color='g', alpha=0.5)\n",
    "\n",
    "# ax.plot(800, 91, marker=\"o\", markersize=10, markeredgecolor=\"red\", markerfacecolor=\"green\")\n",
    "\n",
    "ax.set_title(\"PCA analysis on HOG features of training set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.cumsum(pca_HOG_std.explained_variance_ratio_)*100)[1100]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Remarks: More than 90% of variance is explained by first 1100 components</b>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2. Kaiser's rule in statistics: Pick components which have eigenvalues >= 1 or 0.7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5), tight_layout=True)\n",
    "\n",
    "ax.plot(pca_HOG_std.explained_variance_, 'bo-', linewidth=2)\n",
    "ax.grid(color='r', linestyle='--', linewidth=1)\n",
    "\n",
    "ax.set_yticks(np.arange(0,125,5))\n",
    "ax.set_xticks(np.arange(0,HOG_list.shape[1],100))\n",
    "\n",
    "ax.set_xlabel('Principal Component')\n",
    "ax.set_ylabel('Eigenvalue')\n",
    "plt.axhline(y=1, linewidth=1, color='g', alpha=0.5)\n",
    "plt.title('Scree Plot of PCA: Component Eigenvalues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nEigenvalues \\n%s' %pca_HOG_std.explained_variance_)\n",
    "print('Eigenvectors \\n%s' %pca_HOG_std.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaiser's rule in statistics: Pick components which have eigenvalues >= 1 or 0.7\n",
    "a = pca_HOG_std.explained_variance_ >= 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Only 309 components are significant and should be kept </b>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Fit PCA to the HOG features\n",
    "\n",
    "1. We fit PCA (with n_components to keep) onto the training set\n",
    "2. Transform the training set with that PCA\n",
    "3. Use that PCA to transform the validation & test set\n",
    "\n",
    "##### 4.1. For training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep 1100 components which contribute to > 90 %\n",
    "pca_HOG_std_2 = PCA(n_components=1100)\n",
    "pca_HOG_std_2.fit(HOG_list_std)\n",
    "HOG_PCA_train = pca_HOG_std_2.transform(HOG_list_std)\n",
    "print(\"Original shape:   \", HOG_list_std.shape)\n",
    "print(\"Transformed shape:\", HOG_PCA_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOG for train set --- standardization again\n",
    "std_scale_train_2 = preprocessing.StandardScaler().fit(HOG_PCA_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save in file\n",
    "X_HOG_std_train = std_scale_train_2.transform(HOG_PCA_train)\n",
    "X_HOG_train_dff = pd.DataFrame(data = X_HOG_std_train)\n",
    "X_HOG_train_df = pd.DataFrame(data = dfFoldTraining_1[\"short_filenames\"])\n",
    "\n",
    "X_HOG_train_df = pd.concat([X_HOG_train_df,X_HOG_train_dff], axis=1)\n",
    "X_HOG_train_df.columns = pd.RangeIndex(X_HOG_train_df.columns.size)\n",
    "\n",
    "display(X_HOG_train_df.head(5), X_HOG_train_df.shape)\n",
    "\n",
    "X_HOG_train_df.to_csv(\"..//_inputs//_image_features//new//X-HOG_std_PCA_1100_std-train-fold_1.csv\", header=False, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2. For validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract HOG features for the validation set\n",
    "HOG_validation_list = extract_hog(dfFoldValidation_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard deviation normalization\n",
    "HOG_validation_list_std = train_std_norm.transform(HOG_validation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the HOG features using above PCA fitting\n",
    "HOG_PCA_validation = pca_HOG_std_2.transform(HOG_validation_list_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original shape:   \", HOG_validation_list.shape)\n",
    "print(\"Transformed shape:\", HOG_PCA_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard deviation normalization using above std_scale_train = preprocessing.StandardScaler().fit(HOG_PCA_train)\n",
    "X_HOG_std_validation = std_scale_train_2.transform(HOG_PCA_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_HOG_train_dff = pd.DataFrame(data = X_HOG_std_validation)\n",
    "X_HOG_train_df = pd.DataFrame(data = dfFoldValidation_1[\"short_filenames\"])\n",
    "\n",
    "X_HOG_train_df = pd.concat([X_HOG_train_df,X_HOG_train_dff], axis=1)\n",
    "X_HOG_train_df.columns = pd.RangeIndex(X_HOG_train_df.columns.size)\n",
    "\n",
    "display(X_HOG_train_df.head(5), X_HOG_train_df.shape)\n",
    "\n",
    "X_HOG_train_df.to_csv(\"..//_inputs//_image_features//new//X-HOG_std_PCA_1100_std-validation-fold_1.csv\", header=False, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2. For test set\n",
    "\n",
    "<u><b> Remarks :</b></u> We use 4-fold cross validaiton. Then, we need also to compute each kind of features for test set.\n",
    "So, for the test set, we extract 4 sets of features for each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTest = pd.read_csv('..//_inputs//_images_Zooscan//ZooScan-test_img.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract HOG features for the test set\n",
    "HOG_test_list = extract_hog(dfTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard deviation normalization \n",
    "HOG_test_list_std = train_std_norm.transform(HOG_test_list)\n",
    "# Transform the HOG features using above PCA fitting\n",
    "HOG_PCA_test = pca_HOG_std_2.transform(HOG_test_list_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original shape:   \", HOG_test_list.shape)\n",
    "print(\"Transformed shape:\", HOG_PCA_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard deviation normalization using above std_scale_train = preprocessing.StandardScaler().fit(HOG_PCA_train)\n",
    "X_HOG_std_test = std_scale_train_2.transform(HOG_PCA_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_HOG_train_dff = pd.DataFrame(data = X_HOG_std_test)\n",
    "X_HOG_train_df = pd.DataFrame(data = dfTest[\"short_filenames\"])\n",
    "\n",
    "X_HOG_train_df = pd.concat([X_HOG_train_df,X_HOG_train_dff], axis=1)\n",
    "X_HOG_train_df.columns = pd.RangeIndex(X_HOG_train_df.columns.size)\n",
    "\n",
    "display(X_HOG_train_df.head(5), X_HOG_train_df.shape)\n",
    "\n",
    "X_HOG_train_df.to_csv(\"..//_inputs//_image_features//new//X-HOG_std_PCA_1100_std-test-fold_1.csv\", header=False, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2. For fold 2\n",
    "#### 1. Read path of fold 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFoldTraining_1 = pd.read_csv('..//_inputs//_images_Zooscan//_Zooscan-training-fold_2.csv')\n",
    "dfFoldValidation_1 = pd.read_csv('..//_inputs//_images_Zooscan//_Zooscan-validation-fold_2.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Extracting HOG feature for the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOG_list = extract_hog(dfFoldTraining_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a standard deviation normalization for later uses\n",
    "train_std_norm = StandardScaler().fit(HOG_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard deviation normalization\n",
    "HOG_list_std = train_std_norm.transform(HOG_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HOG_list_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total HOG features:',(HOG_list_std.shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. PCA analysis on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_HOG_std = PCA().fit(HOG_list_std)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1. Plot PCA components and CEV\n",
    "\n",
    "From this, we can know number of components to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5), tight_layout=True)\n",
    "\n",
    "ax.plot(np.cumsum(pca_HOG_std.explained_variance_ratio_)*100, linewidth=2)\n",
    "ax.grid(color='r', linestyle='--', linewidth=1)\n",
    "\n",
    "ax.set_xlabel('Number of components')\n",
    "ax.set_ylabel('Cumulative explained variance');\n",
    "\n",
    "ax.set_yticks(np.arange(0,105,5))\n",
    "ax.set_xticks(np.arange(0,HOG_list.shape[1],100))\n",
    "\n",
    "ax.axhline(y=90, linewidth=3, color='g', alpha=0.5)\n",
    "\n",
    "# ax.plot(800, 91, marker=\"o\", markersize=10, markeredgecolor=\"red\", markerfacecolor=\"green\")\n",
    "\n",
    "ax.set_title(\"PCA analysis on HOG features of training set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.cumsum(pca_HOG_std.explained_variance_ratio_)*100)[1100]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Remarks: More than 90% of variance is explained by first 1100 components</b>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Fit PCA to the HOG features\n",
    "\n",
    "1. We fit PCA (with n_components to keep) onto the training set\n",
    "2. Transform the training set with that PCA\n",
    "3. Use that PCA to transform the validation & test set\n",
    "\n",
    "##### 4.1. For training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep 1100 components which contribute to > 90 %\n",
    "pca_HOG_std_2 = PCA(n_components=1100)\n",
    "pca_HOG_std_2.fit(HOG_list_std)\n",
    "HOG_PCA_train = pca_HOG_std_2.transform(HOG_list_std)\n",
    "print(\"Original shape:   \", HOG_list_std.shape)\n",
    "print(\"Transformed shape:\", HOG_PCA_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOG for train set --- standardization again\n",
    "std_scale_train_2 = preprocessing.StandardScaler().fit(HOG_PCA_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save in file\n",
    "X_HOG_std_train = std_scale_train_2.transform(HOG_PCA_train)\n",
    "X_HOG_train_dff = pd.DataFrame(data = X_HOG_std_train)\n",
    "X_HOG_train_df = pd.DataFrame(data = dfFoldTraining_1[\"short_filenames\"])\n",
    "\n",
    "X_HOG_train_df = pd.concat([X_HOG_train_df,X_HOG_train_dff], axis=1)\n",
    "X_HOG_train_df.columns = pd.RangeIndex(X_HOG_train_df.columns.size)\n",
    "\n",
    "display(X_HOG_train_df.head(5), X_HOG_train_df.shape)\n",
    "\n",
    "X_HOG_train_df.to_csv(\"..//_inputs//_image_features//new//X-HOG_std_PCA_1100_std-train-fold_2.csv\", header=False, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2. For validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract HOG features for the validation set\n",
    "HOG_validation_list = extract_hog(dfFoldValidation_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard deviation normalization\n",
    "HOG_validation_list_std = train_std_norm.transform(HOG_validation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the HOG features using above PCA fitting\n",
    "HOG_PCA_validation = pca_HOG_std_2.transform(HOG_validation_list_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original shape:   \", HOG_validation_list.shape)\n",
    "print(\"Transformed shape:\", HOG_PCA_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard deviation normalization using above std_scale_train = preprocessing.StandardScaler().fit(HOG_PCA_train)\n",
    "X_HOG_std_validation = std_scale_train_2.transform(HOG_PCA_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_HOG_train_dff = pd.DataFrame(data = X_HOG_std_validation)\n",
    "X_HOG_train_df = pd.DataFrame(data = dfFoldValidation_1[\"short_filenames\"])\n",
    "\n",
    "X_HOG_train_df = pd.concat([X_HOG_train_df,X_HOG_train_dff], axis=1)\n",
    "X_HOG_train_df.columns = pd.RangeIndex(X_HOG_train_df.columns.size)\n",
    "\n",
    "display(X_HOG_train_df.head(5), X_HOG_train_df.shape)\n",
    "\n",
    "X_HOG_train_df.to_csv(\"..//_inputs//_image_features//new//X-HOG_std_PCA_1100_std-validation-fold_2.csv\", header=False, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2. For test set\n",
    "\n",
    "<u><b> Remarks :</b></u> We use 4-fold cross validaiton. Then, we need also to compute each kind of features for test set.\n",
    "So, for the test set, we extract 4 sets of features for each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTest = pd.read_csv('..//_inputs//_images_Zooscan//ZooScan-test_img.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract HOG features for the test set\n",
    "HOG_test_list = extract_hog(dfTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard deviation normalization \n",
    "HOG_test_list_std = train_std_norm.transform(HOG_test_list)\n",
    "# Transform the HOG features using above PCA fitting\n",
    "HOG_PCA_test = pca_HOG_std_2.transform(HOG_test_list_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original shape:   \", HOG_test_list.shape)\n",
    "print(\"Transformed shape:\", HOG_PCA_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard deviation normalization using above std_scale_train = preprocessing.StandardScaler().fit(HOG_PCA_train)\n",
    "X_HOG_std_test = std_scale_train_2.transform(HOG_PCA_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_HOG_train_dff = pd.DataFrame(data = X_HOG_std_test)\n",
    "X_HOG_train_df = pd.DataFrame(data = dfTest[\"short_filenames\"])\n",
    "\n",
    "X_HOG_train_df = pd.concat([X_HOG_train_df,X_HOG_train_dff], axis=1)\n",
    "X_HOG_train_df.columns = pd.RangeIndex(X_HOG_train_df.columns.size)\n",
    "\n",
    "display(X_HOG_train_df.head(5), X_HOG_train_df.shape)\n",
    "\n",
    "X_HOG_train_df.to_csv(\"..//_inputs//_image_features//new//X-HOG_std_PCA_1100_std-test-fold_2.csv\", header=False, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image_processing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
