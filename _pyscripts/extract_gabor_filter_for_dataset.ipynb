{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "\n",
    "from random import sample\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "import skimage\n",
    "from skimage import io\n",
    "from skimage.feature import daisy, hog, ORB, local_binary_pattern, SIFT\n",
    "from skimage.color import label2rgb, rgb2gray\n",
    "from skimage.transform import resize, rotate, downscale_local_mean\n",
    "\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "from skimage.util import img_as_float\n",
    "from skimage.filters import gabor_kernel\n",
    "from skimage.filters import threshold_niblack\n",
    "from skimage.morphology import convex_hull_image\n",
    "from skimage.measure import find_contours\n",
    "from skimage import exposure\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import gc\n",
    "\n",
    "from joblib import Parallel, delayed, parallel_backend, cpu_count\n",
    "import psutil\n",
    "\n",
    "from platform import python_version\n",
    "\n",
    "import multiprocessing as mp\n",
    "from more_itertools import chunked\n",
    "\n",
    "import gabor_filters\n",
    "from  gabor_filters import gabor_filter\n",
    "from  gabor_filters import gabor_filter_response\n",
    "\n",
    "import importlib\n",
    "importlib.reload(gabor_filters)\n",
    "importlib.reload(gabor_filters.gabor_filter)\n",
    "importlib.reload(gabor_filters.gabor_filter_response)\n",
    "\n",
    "from gabor_filters.gabor_filter import GaborFilterBank as gbb\n",
    "from gabor_filters.gabor_filter_response import GaborFilteredResponseBank as gbfrb\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.16\n",
      "0.19.3\n"
     ]
    }
   ],
   "source": [
    "print(python_version())\n",
    "print(skimage.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(image):\n",
    "    img_height = image.shape[0]\n",
    "    if img_height < 2000:\n",
    "        return image\n",
    "    \n",
    "    # adaptive thresholding\n",
    "    thresh_niblack = threshold_niblack(image, window_size=25, k=0.8)\n",
    "    binary_niblack = image > thresh_niblack\n",
    "\n",
    "    # make convex hull\n",
    "    chull = convex_hull_image(np.pad(binary_niblack, 3, 'constant', constant_values=0))\n",
    "    \n",
    "    # Find the contours of the main object\n",
    "    contours = find_contours(chull, 0.5)\n",
    "\n",
    "    # Find the largest contour (assumed to be the main object)\n",
    "    largest_contour = max(contours, key=len)\n",
    "\n",
    "    # Compute the bounding box coordinates for the largest contour\n",
    "    min_row, min_col = np.min(largest_contour, axis=0)\n",
    "    max_row, max_col = np.max(largest_contour, axis=0)\n",
    "\n",
    "    # Compute the optimal cropping dimensions based on the bounding box\n",
    "    padding = 10  # Adjust the padding as desired\n",
    "    crop_min_row = int(max(min_row - padding, 0))\n",
    "    crop_min_col = int(max(min_col - padding, 0))\n",
    "    crop_max_row = int(min(max_row + padding, image.shape[0]))\n",
    "    crop_max_col = int(min(max_col + padding, image.shape[1]))\n",
    "\n",
    "    # Crop the image using the computed dimensions\n",
    "    cropped_image = image[crop_min_row:crop_max_row, crop_min_col:crop_max_col]\n",
    "\n",
    "    return cropped_image\n",
    "\n",
    "def image_generator(filepaths):\n",
    "    for filepath in filepaths:\n",
    "        yield io.imread(filepath, as_gray=True)\n",
    "\n",
    "def extract_texture_features(image):   \n",
    "    img = crop_image(image) \n",
    "    # Create Gabor filter bank\n",
    "    fmax = 0.327 # maximum frequency\n",
    "    k = np.sqrt(2) #frequency ratio or factor for selecting filter frequencies\n",
    "    p = 0.5 # crossing point between two consecutive filters, default 0.5\n",
    "    u = 6 #number of frequencies\n",
    "    v = 8 #number of orientation\n",
    "    gamma = 0.5  #smoothting parameter \n",
    "    eta = 0.5  #smoothting parameter of\n",
    "    row = img.shape[0]\n",
    "    col = img.shape[1] # size of image\n",
    "\n",
    "    GaborFilterBank = gbb().create_a_set_of_gabor_filters(fmax, k, p, u, v, row, col, gamma, eta)\n",
    "    \n",
    "    # Filter with the filter bank\n",
    "    GaborFilteredReponses = gbfrb().create_a_set_of_Gabor_filtered_responses(img, GaborFilterBank)\n",
    "\n",
    "    # Convert responses to simple 3-D matrix with normalization\n",
    "    filteredImages = gbfrb().convert_a_set_Gabor_filtered_responses_to_ndarray(GaborFilteredReponses)\n",
    "    \n",
    "    # Get mean and standard deviation of each response as Gabor (texture) features of an input image\n",
    "    nImages = filteredImages.shape[2]\n",
    "    textureFeatures = np.zeros(nImages*2)\n",
    "\n",
    "    index=0\n",
    "    for i in range(0, nImages):\n",
    "        textureFeatures[index] = np.mean(np.abs(filteredImages[:,:,i]));\n",
    "        index = index + 1;\n",
    "        textureFeatures[index] = np.std(np.abs(filteredImages[:,:,i]));\n",
    "        index = index + 1;\n",
    "    \n",
    "    del filteredImages, GaborFilteredReponses, GaborFilterBank\n",
    "    gc.collect()\n",
    "    \n",
    "    return textureFeatures"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. main()\n",
    "\n",
    "### 4.2.1. For fold 1\n",
    "#### 1. Read path of fold 1 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFoldTraining_1 = pd.read_csv('..//_inputs//_images_Zooscan//_Zooscan-training-fold_1.csv')\n",
    "dfFoldValidation_1 = pd.read_csv('..//_inputs//_images_Zooscan//_Zooscan-validation-fold_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filenames</th>\n",
       "      <th>labels</th>\n",
       "      <th>short_filenames</th>\n",
       "      <th>cls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>..//_inputs//_images_Zooscan//_training//aggre...</td>\n",
       "      <td>aggregats_debris</td>\n",
       "      <td>0001-aggregates.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>..//_inputs//_images_Zooscan//_training//aggre...</td>\n",
       "      <td>aggregats_debris</td>\n",
       "      <td>0002.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>..//_inputs//_images_Zooscan//_training//aggre...</td>\n",
       "      <td>aggregats_debris</td>\n",
       "      <td>0003-aggregates.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>..//_inputs//_images_Zooscan//_training//aggre...</td>\n",
       "      <td>aggregats_debris</td>\n",
       "      <td>0004-aggregates.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>..//_inputs//_images_Zooscan//_training//aggre...</td>\n",
       "      <td>aggregats_debris</td>\n",
       "      <td>0004.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           filenames            labels  \\\n",
       "0  ..//_inputs//_images_Zooscan//_training//aggre...  aggregats_debris   \n",
       "1  ..//_inputs//_images_Zooscan//_training//aggre...  aggregats_debris   \n",
       "2  ..//_inputs//_images_Zooscan//_training//aggre...  aggregats_debris   \n",
       "3  ..//_inputs//_images_Zooscan//_training//aggre...  aggregats_debris   \n",
       "4  ..//_inputs//_images_Zooscan//_training//aggre...  aggregats_debris   \n",
       "\n",
       "       short_filenames  cls  \n",
       "0  0001-aggregates.png    0  \n",
       "1             0002.png    0  \n",
       "2  0003-aggregates.png    0  \n",
       "3  0004-aggregates.png    0  \n",
       "4             0004.png    0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(44099, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dfFoldTraining_1.head(5), dfFoldTraining_1.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "count=0\n",
    "for i, filepath in enumerate(dfFoldTraining_1['filenames']):\n",
    "    img = io.imread(filepath, as_gray=True)\n",
    "\n",
    "    img_height = img.shape[0]\n",
    "\n",
    "    if img_height > 2000:\n",
    "        # print(i, filepath)\n",
    "        count +=1\n",
    "\n",
    "display(count)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Extracting gabor feature for the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3a11961d2de4c5bb1438b8adf8ba1b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extract Gabor features:   0%|          | 0/44099 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filepaths = dfFoldTraining_1['filenames']\n",
    "\n",
    "n_files = len(filepaths)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "num_processes = 8\n",
    "\n",
    "gabor_train_list = []\n",
    "\n",
    "# i=0;\n",
    "with tqdm(total=n_files, desc=\"Extract Gabor features\") as pbar:\n",
    "\n",
    "    with Parallel(n_jobs=num_processes) as parallel:\n",
    "\n",
    "        for batch in chunked(image_generator(filepaths), batch_size):\n",
    "            \n",
    "            # i=i+1\n",
    "            # print('Working with batch: ',i)\n",
    "\n",
    "            batch_results = parallel(\n",
    "                delayed(extract_texture_features)(img) for img in batch)\n",
    "            \n",
    "            gabor_train_list.extend(batch_results)\n",
    "\n",
    "            del batch_results\n",
    "            gc.collect()\n",
    "\n",
    "            pbar.update(len(batch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'gabor_train_list' (list)\n"
     ]
    }
   ],
   "source": [
    "%store gabor_train_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ‘%store’ command saves the specified variable. Now if we restart the Jupyter Notebook we can recover the variable using the ‘%store -r’ command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r gabor_train_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44099, 96)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(gabor_train_list).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gabor filter for train set --- standardization \n",
    "std_scale_train = preprocessing.StandardScaler().fit(gabor_train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001-aggregates.png</td>\n",
       "      <td>1.136312</td>\n",
       "      <td>-0.120867</td>\n",
       "      <td>1.151158</td>\n",
       "      <td>-0.114632</td>\n",
       "      <td>1.209658</td>\n",
       "      <td>0.191188</td>\n",
       "      <td>1.300448</td>\n",
       "      <td>0.745374</td>\n",
       "      <td>1.352405</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.742402</td>\n",
       "      <td>-1.194496</td>\n",
       "      <td>-0.721887</td>\n",
       "      <td>-1.174843</td>\n",
       "      <td>-0.721007</td>\n",
       "      <td>-1.183975</td>\n",
       "      <td>-0.732128</td>\n",
       "      <td>-1.221598</td>\n",
       "      <td>-0.744075</td>\n",
       "      <td>-1.200731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002.png</td>\n",
       "      <td>0.232402</td>\n",
       "      <td>-0.388770</td>\n",
       "      <td>0.245820</td>\n",
       "      <td>-0.432895</td>\n",
       "      <td>0.242654</td>\n",
       "      <td>-0.452550</td>\n",
       "      <td>0.217668</td>\n",
       "      <td>-0.430446</td>\n",
       "      <td>0.192616</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220550</td>\n",
       "      <td>-0.009426</td>\n",
       "      <td>-0.510338</td>\n",
       "      <td>-0.274120</td>\n",
       "      <td>-0.623958</td>\n",
       "      <td>-0.310437</td>\n",
       "      <td>-0.607235</td>\n",
       "      <td>-0.319016</td>\n",
       "      <td>-0.582036</td>\n",
       "      <td>-0.387699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003-aggregates.png</td>\n",
       "      <td>1.147477</td>\n",
       "      <td>0.747343</td>\n",
       "      <td>1.118156</td>\n",
       "      <td>0.435737</td>\n",
       "      <td>1.116818</td>\n",
       "      <td>0.321630</td>\n",
       "      <td>1.195342</td>\n",
       "      <td>0.754692</td>\n",
       "      <td>1.287895</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.756436</td>\n",
       "      <td>-0.912781</td>\n",
       "      <td>-0.721888</td>\n",
       "      <td>-0.821082</td>\n",
       "      <td>-0.754551</td>\n",
       "      <td>-0.978059</td>\n",
       "      <td>-0.771848</td>\n",
       "      <td>-1.065330</td>\n",
       "      <td>-0.774409</td>\n",
       "      <td>-1.017040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0004-aggregates.png</td>\n",
       "      <td>-0.492552</td>\n",
       "      <td>0.765120</td>\n",
       "      <td>-0.528705</td>\n",
       "      <td>0.749952</td>\n",
       "      <td>-0.585569</td>\n",
       "      <td>0.758288</td>\n",
       "      <td>-0.627541</td>\n",
       "      <td>0.739659</td>\n",
       "      <td>-0.632524</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.101012</td>\n",
       "      <td>-0.334478</td>\n",
       "      <td>-1.115239</td>\n",
       "      <td>-0.354489</td>\n",
       "      <td>-0.666226</td>\n",
       "      <td>-0.337154</td>\n",
       "      <td>1.038831</td>\n",
       "      <td>0.430920</td>\n",
       "      <td>2.542540</td>\n",
       "      <td>2.356331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004.png</td>\n",
       "      <td>0.659027</td>\n",
       "      <td>-0.766207</td>\n",
       "      <td>0.697820</td>\n",
       "      <td>-0.732164</td>\n",
       "      <td>0.744554</td>\n",
       "      <td>-0.687640</td>\n",
       "      <td>0.749926</td>\n",
       "      <td>-0.640430</td>\n",
       "      <td>0.692348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158381</td>\n",
       "      <td>-0.283880</td>\n",
       "      <td>-0.428167</td>\n",
       "      <td>-0.801556</td>\n",
       "      <td>-0.787669</td>\n",
       "      <td>-0.932667</td>\n",
       "      <td>-0.801749</td>\n",
       "      <td>-0.928621</td>\n",
       "      <td>-0.763943</td>\n",
       "      <td>-0.889699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0         1         2         3         4         5   \\\n",
       "0  0001-aggregates.png  1.136312 -0.120867  1.151158 -0.114632  1.209658   \n",
       "1             0002.png  0.232402 -0.388770  0.245820 -0.432895  0.242654   \n",
       "2  0003-aggregates.png  1.147477  0.747343  1.118156  0.435737  1.116818   \n",
       "3  0004-aggregates.png -0.492552  0.765120 -0.528705  0.749952 -0.585569   \n",
       "4             0004.png  0.659027 -0.766207  0.697820 -0.732164  0.744554   \n",
       "\n",
       "         6         7         8         9   ...        87        88        89  \\\n",
       "0  0.191188  1.300448  0.745374  1.352405  ... -0.742402 -1.194496 -0.721887   \n",
       "1 -0.452550  0.217668 -0.430446  0.192616  ...  0.220550 -0.009426 -0.510338   \n",
       "2  0.321630  1.195342  0.754692  1.287895  ... -0.756436 -0.912781 -0.721888   \n",
       "3  0.758288 -0.627541  0.739659 -0.632524  ... -1.101012 -0.334478 -1.115239   \n",
       "4 -0.687640  0.749926 -0.640430  0.692348  ...  0.158381 -0.283880 -0.428167   \n",
       "\n",
       "         90        91        92        93        94        95        96  \n",
       "0 -1.174843 -0.721007 -1.183975 -0.732128 -1.221598 -0.744075 -1.200731  \n",
       "1 -0.274120 -0.623958 -0.310437 -0.607235 -0.319016 -0.582036 -0.387699  \n",
       "2 -0.821082 -0.754551 -0.978059 -0.771848 -1.065330 -0.774409 -1.017040  \n",
       "3 -0.354489 -0.666226 -0.337154  1.038831  0.430920  2.542540  2.356331  \n",
       "4 -0.801556 -0.787669 -0.932667 -0.801749 -0.928621 -0.763943 -0.889699  \n",
       "\n",
       "[5 rows x 97 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(44099, 97)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save in file\n",
    "X_gabor_std_train = std_scale_train.transform(gabor_train_list)\n",
    "X_gabor_train_dff = pd.DataFrame(data = X_gabor_std_train)\n",
    "X_gabor_train_df = pd.DataFrame(data = dfFoldTraining_1[\"short_filenames\"])\n",
    "\n",
    "X_gabor_train_df = pd.concat([X_gabor_train_df,X_gabor_train_dff], axis=1)\n",
    "X_gabor_train_df.columns = pd.RangeIndex(X_gabor_train_df.columns.size)\n",
    "\n",
    "display(X_gabor_train_df.head(5), X_gabor_train_df.shape)\n",
    "\n",
    "X_gabor_train_df.to_csv(\"..//_inputs//_image_features//new//X-gabor_std_96-train-fold_1.csv\", header=False, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2. For validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f4254beab2242bfb7d12f29d35df82f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extract Gabor features:   0%|          | 0/14700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filepaths = dfFoldValidation_1['filenames']\n",
    "\n",
    "n_files = len(filepaths)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "num_processes = 8\n",
    "\n",
    "gabor_validation_list = []\n",
    "\n",
    "# i=0;\n",
    "with tqdm(total=n_files, desc=\"Extract Gabor features\") as pbar:\n",
    "\n",
    "    with Parallel(n_jobs=num_processes) as parallel:\n",
    "\n",
    "        for batch in chunked(image_generator(filepaths), batch_size):\n",
    "            \n",
    "            # i=i+1\n",
    "            # print('Working with batch: ',i)\n",
    "\n",
    "            batch_results = parallel(\n",
    "                delayed(extract_texture_features)(img) for img in batch)\n",
    "            \n",
    "            gabor_validation_list.extend(batch_results)\n",
    "\n",
    "            del batch_results\n",
    "            gc.collect()\n",
    "\n",
    "            pbar.update(len(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard deviation normalization using above std_scale_train = preprocessing.StandardScaler().fit(gabor_train_list)\n",
    "X_gabor_std_validation = std_scale_train.transform(gabor_validation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002-aggregates.png</td>\n",
       "      <td>-1.124807</td>\n",
       "      <td>0.846440</td>\n",
       "      <td>-1.138088</td>\n",
       "      <td>0.866766</td>\n",
       "      <td>-1.149040</td>\n",
       "      <td>0.865567</td>\n",
       "      <td>-1.170127</td>\n",
       "      <td>0.882358</td>\n",
       "      <td>-1.165774</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018641</td>\n",
       "      <td>0.365488</td>\n",
       "      <td>0.462320</td>\n",
       "      <td>0.610102</td>\n",
       "      <td>0.639254</td>\n",
       "      <td>0.854176</td>\n",
       "      <td>0.087541</td>\n",
       "      <td>0.243078</td>\n",
       "      <td>0.794500</td>\n",
       "      <td>0.856870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0006-aggregates.png</td>\n",
       "      <td>0.583940</td>\n",
       "      <td>-0.551095</td>\n",
       "      <td>0.573031</td>\n",
       "      <td>-0.542108</td>\n",
       "      <td>0.564279</td>\n",
       "      <td>-0.574851</td>\n",
       "      <td>0.556822</td>\n",
       "      <td>-0.644346</td>\n",
       "      <td>0.564660</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.534824</td>\n",
       "      <td>-0.458842</td>\n",
       "      <td>-0.467645</td>\n",
       "      <td>-0.587663</td>\n",
       "      <td>-0.184629</td>\n",
       "      <td>-0.352692</td>\n",
       "      <td>0.289746</td>\n",
       "      <td>0.295499</td>\n",
       "      <td>0.325833</td>\n",
       "      <td>0.408612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001-aggregates-jo_700_05.png</td>\n",
       "      <td>-0.452301</td>\n",
       "      <td>0.901055</td>\n",
       "      <td>-0.440633</td>\n",
       "      <td>0.929559</td>\n",
       "      <td>-0.418416</td>\n",
       "      <td>0.959422</td>\n",
       "      <td>-0.391965</td>\n",
       "      <td>0.993847</td>\n",
       "      <td>-0.382175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.383506</td>\n",
       "      <td>1.067756</td>\n",
       "      <td>0.131348</td>\n",
       "      <td>0.300736</td>\n",
       "      <td>-0.340842</td>\n",
       "      <td>0.092228</td>\n",
       "      <td>-0.424322</td>\n",
       "      <td>0.215652</td>\n",
       "      <td>-0.450190</td>\n",
       "      <td>0.159132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0010-aggregates.png</td>\n",
       "      <td>0.553547</td>\n",
       "      <td>-0.551249</td>\n",
       "      <td>0.559949</td>\n",
       "      <td>-0.522796</td>\n",
       "      <td>0.566758</td>\n",
       "      <td>-0.474370</td>\n",
       "      <td>0.565353</td>\n",
       "      <td>-0.468133</td>\n",
       "      <td>0.551870</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208128</td>\n",
       "      <td>-0.346751</td>\n",
       "      <td>-0.063954</td>\n",
       "      <td>-0.113626</td>\n",
       "      <td>-0.114338</td>\n",
       "      <td>-0.329164</td>\n",
       "      <td>-0.289741</td>\n",
       "      <td>-0.405385</td>\n",
       "      <td>-0.460871</td>\n",
       "      <td>-0.544875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0011.png</td>\n",
       "      <td>0.878954</td>\n",
       "      <td>-1.234502</td>\n",
       "      <td>0.870033</td>\n",
       "      <td>-1.165677</td>\n",
       "      <td>0.867735</td>\n",
       "      <td>-1.162138</td>\n",
       "      <td>0.873726</td>\n",
       "      <td>-1.118144</td>\n",
       "      <td>0.914043</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.775883</td>\n",
       "      <td>-1.183196</td>\n",
       "      <td>-0.431509</td>\n",
       "      <td>-0.765326</td>\n",
       "      <td>0.178111</td>\n",
       "      <td>-0.425520</td>\n",
       "      <td>-0.282132</td>\n",
       "      <td>-0.658629</td>\n",
       "      <td>-0.743051</td>\n",
       "      <td>-1.142364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0         1         2         3         4   \\\n",
       "0           0002-aggregates.png -1.124807  0.846440 -1.138088  0.866766   \n",
       "1           0006-aggregates.png  0.583940 -0.551095  0.573031 -0.542108   \n",
       "2  001-aggregates-jo_700_05.png -0.452301  0.901055 -0.440633  0.929559   \n",
       "3           0010-aggregates.png  0.553547 -0.551249  0.559949 -0.522796   \n",
       "4                      0011.png  0.878954 -1.234502  0.870033 -1.165677   \n",
       "\n",
       "         5         6         7         8         9   ...        87        88  \\\n",
       "0 -1.149040  0.865567 -1.170127  0.882358 -1.165774  ... -0.018641  0.365488   \n",
       "1  0.564279 -0.574851  0.556822 -0.644346  0.564660  ... -0.534824 -0.458842   \n",
       "2 -0.418416  0.959422 -0.391965  0.993847 -0.382175  ...  0.383506  1.067756   \n",
       "3  0.566758 -0.474370  0.565353 -0.468133  0.551870  ... -0.208128 -0.346751   \n",
       "4  0.867735 -1.162138  0.873726 -1.118144  0.914043  ... -0.775883 -1.183196   \n",
       "\n",
       "         89        90        91        92        93        94        95  \\\n",
       "0  0.462320  0.610102  0.639254  0.854176  0.087541  0.243078  0.794500   \n",
       "1 -0.467645 -0.587663 -0.184629 -0.352692  0.289746  0.295499  0.325833   \n",
       "2  0.131348  0.300736 -0.340842  0.092228 -0.424322  0.215652 -0.450190   \n",
       "3 -0.063954 -0.113626 -0.114338 -0.329164 -0.289741 -0.405385 -0.460871   \n",
       "4 -0.431509 -0.765326  0.178111 -0.425520 -0.282132 -0.658629 -0.743051   \n",
       "\n",
       "         96  \n",
       "0  0.856870  \n",
       "1  0.408612  \n",
       "2  0.159132  \n",
       "3 -0.544875  \n",
       "4 -1.142364  \n",
       "\n",
       "[5 rows x 97 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(14700, 97)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_gabor_validation_dff = pd.DataFrame(data = X_gabor_std_validation)\n",
    "X_gabor_validation_df = pd.DataFrame(data = dfFoldValidation_1[\"short_filenames\"])\n",
    "\n",
    "X_gabor_validation_df = pd.concat([X_gabor_validation_df,X_gabor_validation_dff], axis=1)\n",
    "X_gabor_validation_df.columns = pd.RangeIndex(X_gabor_validation_df.columns.size)\n",
    "\n",
    "display(X_gabor_validation_df.head(5), X_gabor_validation_df.shape)\n",
    "\n",
    "X_gabor_validation_df.to_csv(\"..//_inputs//_image_features//new//X-gabor_std_96_std-validation-fold_1.csv\", header=False, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2. For test set\n",
    "\n",
    "<u><b> Remarks :</b></u> We use 4-fold cross validaiton. Then, we need also to compute each kind of features for test set.\n",
    "So, for the test set, we extract 4 sets of features for each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTest = pd.read_csv('..//_inputs//_images_Zooscan//ZooScan-test_img.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4ad1cb1bd324b1594ade4200755768f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extract Gabor features:   0%|          | 0/6907 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filepaths = dfTest['filenames']\n",
    "\n",
    "n_files = len(filepaths)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "num_processes = 8\n",
    "\n",
    "gabor_test_list = []\n",
    "\n",
    "# i=0;\n",
    "with tqdm(total=n_files, desc=\"Extract Gabor features\") as pbar:\n",
    "\n",
    "    with Parallel(n_jobs=num_processes) as parallel:\n",
    "\n",
    "        for batch in chunked(image_generator(filepaths), batch_size):\n",
    "            \n",
    "            # i=i+1\n",
    "            # print('Working with batch: ',i)\n",
    "\n",
    "            batch_results = parallel(\n",
    "                delayed(extract_texture_features)(img) for img in batch)\n",
    "            \n",
    "            gabor_test_list.extend(batch_results)\n",
    "\n",
    "            del batch_results\n",
    "            gc.collect()\n",
    "\n",
    "            pbar.update(len(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard deviation normalization using above std_scale_train = preprocessing.StandardScaler().fit(gabor_test_list)\n",
    "X_gabor_std_test = std_scale_train.transform(gabor_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0007-aggregates_002.png</td>\n",
       "      <td>0.697323</td>\n",
       "      <td>-0.808015</td>\n",
       "      <td>0.695685</td>\n",
       "      <td>-0.813086</td>\n",
       "      <td>0.693752</td>\n",
       "      <td>-0.834384</td>\n",
       "      <td>0.683842</td>\n",
       "      <td>-0.861493</td>\n",
       "      <td>0.679107</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232577</td>\n",
       "      <td>-0.321633</td>\n",
       "      <td>-0.253101</td>\n",
       "      <td>-0.322692</td>\n",
       "      <td>-0.281572</td>\n",
       "      <td>-0.410231</td>\n",
       "      <td>-0.389857</td>\n",
       "      <td>-0.496872</td>\n",
       "      <td>-0.442787</td>\n",
       "      <td>-0.573586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0009-aggregates_001.png</td>\n",
       "      <td>1.071954</td>\n",
       "      <td>-1.023312</td>\n",
       "      <td>1.050105</td>\n",
       "      <td>-1.159215</td>\n",
       "      <td>1.029900</td>\n",
       "      <td>-1.328477</td>\n",
       "      <td>1.038799</td>\n",
       "      <td>-1.405424</td>\n",
       "      <td>1.051676</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.654648</td>\n",
       "      <td>-1.133130</td>\n",
       "      <td>-0.634690</td>\n",
       "      <td>-1.126482</td>\n",
       "      <td>-0.661392</td>\n",
       "      <td>-1.095521</td>\n",
       "      <td>-0.674366</td>\n",
       "      <td>-1.084152</td>\n",
       "      <td>-0.634005</td>\n",
       "      <td>-1.124700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0012-aggregates_002.png</td>\n",
       "      <td>1.178067</td>\n",
       "      <td>-1.612691</td>\n",
       "      <td>1.175463</td>\n",
       "      <td>-1.609940</td>\n",
       "      <td>1.168327</td>\n",
       "      <td>-1.605932</td>\n",
       "      <td>1.153877</td>\n",
       "      <td>-1.553238</td>\n",
       "      <td>1.146037</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.569331</td>\n",
       "      <td>-1.130898</td>\n",
       "      <td>-0.609587</td>\n",
       "      <td>-1.272601</td>\n",
       "      <td>-0.602741</td>\n",
       "      <td>-1.309572</td>\n",
       "      <td>-0.584470</td>\n",
       "      <td>-1.288972</td>\n",
       "      <td>-0.586553</td>\n",
       "      <td>-1.250737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002-aggregates_001.png</td>\n",
       "      <td>0.427048</td>\n",
       "      <td>-0.522704</td>\n",
       "      <td>0.205709</td>\n",
       "      <td>-0.306068</td>\n",
       "      <td>0.020965</td>\n",
       "      <td>-0.079924</td>\n",
       "      <td>-0.031241</td>\n",
       "      <td>-0.103162</td>\n",
       "      <td>-0.010247</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.046277</td>\n",
       "      <td>-0.396232</td>\n",
       "      <td>-0.878527</td>\n",
       "      <td>-0.259588</td>\n",
       "      <td>-0.606440</td>\n",
       "      <td>-0.084636</td>\n",
       "      <td>-0.335342</td>\n",
       "      <td>0.174256</td>\n",
       "      <td>-0.090707</td>\n",
       "      <td>0.027752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002-aggregates_007.png</td>\n",
       "      <td>-0.449403</td>\n",
       "      <td>1.010885</td>\n",
       "      <td>-0.441765</td>\n",
       "      <td>1.021145</td>\n",
       "      <td>-0.439187</td>\n",
       "      <td>1.020487</td>\n",
       "      <td>-0.447650</td>\n",
       "      <td>1.000680</td>\n",
       "      <td>-0.452431</td>\n",
       "      <td>...</td>\n",
       "      <td>1.371099</td>\n",
       "      <td>1.642061</td>\n",
       "      <td>0.863731</td>\n",
       "      <td>1.276360</td>\n",
       "      <td>0.259719</td>\n",
       "      <td>0.622112</td>\n",
       "      <td>-0.047238</td>\n",
       "      <td>0.272648</td>\n",
       "      <td>-0.308480</td>\n",
       "      <td>-0.130846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0         1         2         3         4         5   \\\n",
       "0  0007-aggregates_002.png  0.697323 -0.808015  0.695685 -0.813086  0.693752   \n",
       "1  0009-aggregates_001.png  1.071954 -1.023312  1.050105 -1.159215  1.029900   \n",
       "2  0012-aggregates_002.png  1.178067 -1.612691  1.175463 -1.609940  1.168327   \n",
       "3   002-aggregates_001.png  0.427048 -0.522704  0.205709 -0.306068  0.020965   \n",
       "4   002-aggregates_007.png -0.449403  1.010885 -0.441765  1.021145 -0.439187   \n",
       "\n",
       "         6         7         8         9   ...        87        88        89  \\\n",
       "0 -0.834384  0.683842 -0.861493  0.679107  ... -0.232577 -0.321633 -0.253101   \n",
       "1 -1.328477  1.038799 -1.405424  1.051676  ... -0.654648 -1.133130 -0.634690   \n",
       "2 -1.605932  1.153877 -1.553238  1.146037  ... -0.569331 -1.130898 -0.609587   \n",
       "3 -0.079924 -0.031241 -0.103162 -0.010247  ... -1.046277 -0.396232 -0.878527   \n",
       "4  1.020487 -0.447650  1.000680 -0.452431  ...  1.371099  1.642061  0.863731   \n",
       "\n",
       "         90        91        92        93        94        95        96  \n",
       "0 -0.322692 -0.281572 -0.410231 -0.389857 -0.496872 -0.442787 -0.573586  \n",
       "1 -1.126482 -0.661392 -1.095521 -0.674366 -1.084152 -0.634005 -1.124700  \n",
       "2 -1.272601 -0.602741 -1.309572 -0.584470 -1.288972 -0.586553 -1.250737  \n",
       "3 -0.259588 -0.606440 -0.084636 -0.335342  0.174256 -0.090707  0.027752  \n",
       "4  1.276360  0.259719  0.622112 -0.047238  0.272648 -0.308480 -0.130846  \n",
       "\n",
       "[5 rows x 97 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(6907, 97)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_gabor_test_dff = pd.DataFrame(data = X_gabor_std_test)\n",
    "X_gabor_test_df = pd.DataFrame(data = dfTest[\"short_filenames\"])\n",
    "\n",
    "X_gabor_test_df = pd.concat([X_gabor_test_df,X_gabor_test_dff], axis=1)\n",
    "X_gabor_test_df.columns = pd.RangeIndex(X_gabor_test_df.columns.size)\n",
    "\n",
    "display(X_gabor_test_df.head(5), X_gabor_test_df.shape)\n",
    "\n",
    "X_gabor_test_df.to_csv(\"..//_inputs//_image_features//new//X-gabor_96_std-test-fold_1.csv\", header=False, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2. For fold 2\n",
    "#### 1. Read path of fold 2 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFoldTraining_1 = pd.read_csv('..//_inputs//_images_Zooscan//_Zooscan-training-fold_2.csv')\n",
    "dfFoldValidation_1 = pd.read_csv('..//_inputs//_images_Zooscan//_Zooscan-validation-fold_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filenames</th>\n",
       "      <th>labels</th>\n",
       "      <th>short_filenames</th>\n",
       "      <th>cls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>..//_inputs//_images_Zooscan//_training//aggre...</td>\n",
       "      <td>aggregats_debris</td>\n",
       "      <td>0001-aggregates.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>..//_inputs//_images_Zooscan//_training//aggre...</td>\n",
       "      <td>aggregats_debris</td>\n",
       "      <td>0002-aggregates.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>..//_inputs//_images_Zooscan//_training//aggre...</td>\n",
       "      <td>aggregats_debris</td>\n",
       "      <td>0004-aggregates.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>..//_inputs//_images_Zooscan//_training//aggre...</td>\n",
       "      <td>aggregats_debris</td>\n",
       "      <td>0004.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>..//_inputs//_images_Zooscan//_training//aggre...</td>\n",
       "      <td>aggregats_debris</td>\n",
       "      <td>0005-aggregates.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           filenames            labels  \\\n",
       "0  ..//_inputs//_images_Zooscan//_training//aggre...  aggregats_debris   \n",
       "1  ..//_inputs//_images_Zooscan//_training//aggre...  aggregats_debris   \n",
       "2  ..//_inputs//_images_Zooscan//_training//aggre...  aggregats_debris   \n",
       "3  ..//_inputs//_images_Zooscan//_training//aggre...  aggregats_debris   \n",
       "4  ..//_inputs//_images_Zooscan//_training//aggre...  aggregats_debris   \n",
       "\n",
       "       short_filenames  cls  \n",
       "0  0001-aggregates.png    0  \n",
       "1  0002-aggregates.png    0  \n",
       "2  0004-aggregates.png    0  \n",
       "3             0004.png    0  \n",
       "4  0005-aggregates.png    0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(44099, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dfFoldTraining_1.head(5), dfFoldTraining_1.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "count=0\n",
    "for i, filepath in enumerate(dfFoldTraining_1['filenames']):\n",
    "    img = io.imread(filepath, as_gray=True)\n",
    "\n",
    "    img_height = img.shape[0]\n",
    "\n",
    "    if img_height > 2000:\n",
    "        # print(i, filepath)\n",
    "        count +=1\n",
    "\n",
    "display(count)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Extracting gabor feature for the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5774992b30e5484c97597408f8db5696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extract Gabor features:   0%|          | 0/44099 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filepaths = dfFoldTraining_1['filenames']\n",
    "\n",
    "n_files = len(filepaths)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "num_processes = 8\n",
    "\n",
    "gabor_train_list = []\n",
    "\n",
    "# i=0;\n",
    "with tqdm(total=n_files, desc=\"Extract Gabor features\") as pbar:\n",
    "\n",
    "    with Parallel(n_jobs=num_processes) as parallel:\n",
    "\n",
    "        for batch in chunked(image_generator(filepaths), batch_size):\n",
    "            \n",
    "            # i=i+1\n",
    "            # print('Working with batch: ',i)\n",
    "\n",
    "            batch_results = parallel(\n",
    "                delayed(extract_texture_features)(img) for img in batch)\n",
    "            \n",
    "            gabor_train_list.extend(batch_results)\n",
    "\n",
    "            del batch_results\n",
    "            gc.collect()\n",
    "\n",
    "            pbar.update(len(batch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'gabor_train_list' (list)\n"
     ]
    }
   ],
   "source": [
    "%store gabor_train_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ‘%store’ command saves the specified variable. Now if we restart the Jupyter Notebook we can recover the variable using the ‘%store -r’ command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r gabor_train_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44099, 96)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.asarray(gabor_train_list).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gabor filter for train set --- standardization \n",
    "std_scale_train = preprocessing.StandardScaler().fit(gabor_train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001-aggregates.png</td>\n",
       "      <td>1.136312</td>\n",
       "      <td>-0.120867</td>\n",
       "      <td>1.151158</td>\n",
       "      <td>-0.114632</td>\n",
       "      <td>1.209658</td>\n",
       "      <td>0.191188</td>\n",
       "      <td>1.300448</td>\n",
       "      <td>0.745374</td>\n",
       "      <td>1.352405</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.742402</td>\n",
       "      <td>-1.194496</td>\n",
       "      <td>-0.721887</td>\n",
       "      <td>-1.174843</td>\n",
       "      <td>-0.721007</td>\n",
       "      <td>-1.183975</td>\n",
       "      <td>-0.732128</td>\n",
       "      <td>-1.221598</td>\n",
       "      <td>-0.744075</td>\n",
       "      <td>-1.200731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002.png</td>\n",
       "      <td>0.232402</td>\n",
       "      <td>-0.388770</td>\n",
       "      <td>0.245820</td>\n",
       "      <td>-0.432895</td>\n",
       "      <td>0.242654</td>\n",
       "      <td>-0.452550</td>\n",
       "      <td>0.217668</td>\n",
       "      <td>-0.430446</td>\n",
       "      <td>0.192616</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220550</td>\n",
       "      <td>-0.009426</td>\n",
       "      <td>-0.510338</td>\n",
       "      <td>-0.274120</td>\n",
       "      <td>-0.623958</td>\n",
       "      <td>-0.310437</td>\n",
       "      <td>-0.607235</td>\n",
       "      <td>-0.319016</td>\n",
       "      <td>-0.582036</td>\n",
       "      <td>-0.387699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003-aggregates.png</td>\n",
       "      <td>1.147477</td>\n",
       "      <td>0.747343</td>\n",
       "      <td>1.118156</td>\n",
       "      <td>0.435737</td>\n",
       "      <td>1.116818</td>\n",
       "      <td>0.321630</td>\n",
       "      <td>1.195342</td>\n",
       "      <td>0.754692</td>\n",
       "      <td>1.287895</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.756436</td>\n",
       "      <td>-0.912781</td>\n",
       "      <td>-0.721888</td>\n",
       "      <td>-0.821082</td>\n",
       "      <td>-0.754551</td>\n",
       "      <td>-0.978059</td>\n",
       "      <td>-0.771848</td>\n",
       "      <td>-1.065330</td>\n",
       "      <td>-0.774409</td>\n",
       "      <td>-1.017040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0004-aggregates.png</td>\n",
       "      <td>-0.492552</td>\n",
       "      <td>0.765120</td>\n",
       "      <td>-0.528705</td>\n",
       "      <td>0.749952</td>\n",
       "      <td>-0.585569</td>\n",
       "      <td>0.758288</td>\n",
       "      <td>-0.627541</td>\n",
       "      <td>0.739659</td>\n",
       "      <td>-0.632524</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.101012</td>\n",
       "      <td>-0.334478</td>\n",
       "      <td>-1.115239</td>\n",
       "      <td>-0.354489</td>\n",
       "      <td>-0.666226</td>\n",
       "      <td>-0.337154</td>\n",
       "      <td>1.038831</td>\n",
       "      <td>0.430920</td>\n",
       "      <td>2.542540</td>\n",
       "      <td>2.356331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004.png</td>\n",
       "      <td>0.659027</td>\n",
       "      <td>-0.766207</td>\n",
       "      <td>0.697820</td>\n",
       "      <td>-0.732164</td>\n",
       "      <td>0.744554</td>\n",
       "      <td>-0.687640</td>\n",
       "      <td>0.749926</td>\n",
       "      <td>-0.640430</td>\n",
       "      <td>0.692348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158381</td>\n",
       "      <td>-0.283880</td>\n",
       "      <td>-0.428167</td>\n",
       "      <td>-0.801556</td>\n",
       "      <td>-0.787669</td>\n",
       "      <td>-0.932667</td>\n",
       "      <td>-0.801749</td>\n",
       "      <td>-0.928621</td>\n",
       "      <td>-0.763943</td>\n",
       "      <td>-0.889699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0         1         2         3         4         5   \\\n",
       "0  0001-aggregates.png  1.136312 -0.120867  1.151158 -0.114632  1.209658   \n",
       "1             0002.png  0.232402 -0.388770  0.245820 -0.432895  0.242654   \n",
       "2  0003-aggregates.png  1.147477  0.747343  1.118156  0.435737  1.116818   \n",
       "3  0004-aggregates.png -0.492552  0.765120 -0.528705  0.749952 -0.585569   \n",
       "4             0004.png  0.659027 -0.766207  0.697820 -0.732164  0.744554   \n",
       "\n",
       "         6         7         8         9   ...        87        88        89  \\\n",
       "0  0.191188  1.300448  0.745374  1.352405  ... -0.742402 -1.194496 -0.721887   \n",
       "1 -0.452550  0.217668 -0.430446  0.192616  ...  0.220550 -0.009426 -0.510338   \n",
       "2  0.321630  1.195342  0.754692  1.287895  ... -0.756436 -0.912781 -0.721888   \n",
       "3  0.758288 -0.627541  0.739659 -0.632524  ... -1.101012 -0.334478 -1.115239   \n",
       "4 -0.687640  0.749926 -0.640430  0.692348  ...  0.158381 -0.283880 -0.428167   \n",
       "\n",
       "         90        91        92        93        94        95        96  \n",
       "0 -1.174843 -0.721007 -1.183975 -0.732128 -1.221598 -0.744075 -1.200731  \n",
       "1 -0.274120 -0.623958 -0.310437 -0.607235 -0.319016 -0.582036 -0.387699  \n",
       "2 -0.821082 -0.754551 -0.978059 -0.771848 -1.065330 -0.774409 -1.017040  \n",
       "3 -0.354489 -0.666226 -0.337154  1.038831  0.430920  2.542540  2.356331  \n",
       "4 -0.801556 -0.787669 -0.932667 -0.801749 -0.928621 -0.763943 -0.889699  \n",
       "\n",
       "[5 rows x 97 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(44099, 97)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save in file\n",
    "X_gabor_std_train = std_scale_train.transform(gabor_train_list)\n",
    "X_gabor_train_dff = pd.DataFrame(data = X_gabor_std_train)\n",
    "X_gabor_train_df = pd.DataFrame(data = dfFoldTraining_1[\"short_filenames\"])\n",
    "\n",
    "X_gabor_train_df = pd.concat([X_gabor_train_df,X_gabor_train_dff], axis=1)\n",
    "X_gabor_train_df.columns = pd.RangeIndex(X_gabor_train_df.columns.size)\n",
    "\n",
    "display(X_gabor_train_df.head(5), X_gabor_train_df.shape)\n",
    "\n",
    "X_gabor_train_df.to_csv(\"..//_inputs//_image_features//new//X-gabor_std_96-train-fold_1.csv\", header=False, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2. For validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f4254beab2242bfb7d12f29d35df82f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extract Gabor features:   0%|          | 0/14700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filepaths = dfFoldValidation_1['filenames']\n",
    "\n",
    "n_files = len(filepaths)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "num_processes = 8\n",
    "\n",
    "gabor_validation_list = []\n",
    "\n",
    "# i=0;\n",
    "with tqdm(total=n_files, desc=\"Extract Gabor features\") as pbar:\n",
    "\n",
    "    with Parallel(n_jobs=num_processes) as parallel:\n",
    "\n",
    "        for batch in chunked(image_generator(filepaths), batch_size):\n",
    "            \n",
    "            # i=i+1\n",
    "            # print('Working with batch: ',i)\n",
    "\n",
    "            batch_results = parallel(\n",
    "                delayed(extract_texture_features)(img) for img in batch)\n",
    "            \n",
    "            gabor_validation_list.extend(batch_results)\n",
    "\n",
    "            del batch_results\n",
    "            gc.collect()\n",
    "\n",
    "            pbar.update(len(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard deviation normalization using above std_scale_train = preprocessing.StandardScaler().fit(gabor_train_list)\n",
    "X_gabor_std_validation = std_scale_train.transform(gabor_validation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002-aggregates.png</td>\n",
       "      <td>-1.124807</td>\n",
       "      <td>0.846440</td>\n",
       "      <td>-1.138088</td>\n",
       "      <td>0.866766</td>\n",
       "      <td>-1.149040</td>\n",
       "      <td>0.865567</td>\n",
       "      <td>-1.170127</td>\n",
       "      <td>0.882358</td>\n",
       "      <td>-1.165774</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018641</td>\n",
       "      <td>0.365488</td>\n",
       "      <td>0.462320</td>\n",
       "      <td>0.610102</td>\n",
       "      <td>0.639254</td>\n",
       "      <td>0.854176</td>\n",
       "      <td>0.087541</td>\n",
       "      <td>0.243078</td>\n",
       "      <td>0.794500</td>\n",
       "      <td>0.856870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0006-aggregates.png</td>\n",
       "      <td>0.583940</td>\n",
       "      <td>-0.551095</td>\n",
       "      <td>0.573031</td>\n",
       "      <td>-0.542108</td>\n",
       "      <td>0.564279</td>\n",
       "      <td>-0.574851</td>\n",
       "      <td>0.556822</td>\n",
       "      <td>-0.644346</td>\n",
       "      <td>0.564660</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.534824</td>\n",
       "      <td>-0.458842</td>\n",
       "      <td>-0.467645</td>\n",
       "      <td>-0.587663</td>\n",
       "      <td>-0.184629</td>\n",
       "      <td>-0.352692</td>\n",
       "      <td>0.289746</td>\n",
       "      <td>0.295499</td>\n",
       "      <td>0.325833</td>\n",
       "      <td>0.408612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001-aggregates-jo_700_05.png</td>\n",
       "      <td>-0.452301</td>\n",
       "      <td>0.901055</td>\n",
       "      <td>-0.440633</td>\n",
       "      <td>0.929559</td>\n",
       "      <td>-0.418416</td>\n",
       "      <td>0.959422</td>\n",
       "      <td>-0.391965</td>\n",
       "      <td>0.993847</td>\n",
       "      <td>-0.382175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.383506</td>\n",
       "      <td>1.067756</td>\n",
       "      <td>0.131348</td>\n",
       "      <td>0.300736</td>\n",
       "      <td>-0.340842</td>\n",
       "      <td>0.092228</td>\n",
       "      <td>-0.424322</td>\n",
       "      <td>0.215652</td>\n",
       "      <td>-0.450190</td>\n",
       "      <td>0.159132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0010-aggregates.png</td>\n",
       "      <td>0.553547</td>\n",
       "      <td>-0.551249</td>\n",
       "      <td>0.559949</td>\n",
       "      <td>-0.522796</td>\n",
       "      <td>0.566758</td>\n",
       "      <td>-0.474370</td>\n",
       "      <td>0.565353</td>\n",
       "      <td>-0.468133</td>\n",
       "      <td>0.551870</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208128</td>\n",
       "      <td>-0.346751</td>\n",
       "      <td>-0.063954</td>\n",
       "      <td>-0.113626</td>\n",
       "      <td>-0.114338</td>\n",
       "      <td>-0.329164</td>\n",
       "      <td>-0.289741</td>\n",
       "      <td>-0.405385</td>\n",
       "      <td>-0.460871</td>\n",
       "      <td>-0.544875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0011.png</td>\n",
       "      <td>0.878954</td>\n",
       "      <td>-1.234502</td>\n",
       "      <td>0.870033</td>\n",
       "      <td>-1.165677</td>\n",
       "      <td>0.867735</td>\n",
       "      <td>-1.162138</td>\n",
       "      <td>0.873726</td>\n",
       "      <td>-1.118144</td>\n",
       "      <td>0.914043</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.775883</td>\n",
       "      <td>-1.183196</td>\n",
       "      <td>-0.431509</td>\n",
       "      <td>-0.765326</td>\n",
       "      <td>0.178111</td>\n",
       "      <td>-0.425520</td>\n",
       "      <td>-0.282132</td>\n",
       "      <td>-0.658629</td>\n",
       "      <td>-0.743051</td>\n",
       "      <td>-1.142364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0         1         2         3         4   \\\n",
       "0           0002-aggregates.png -1.124807  0.846440 -1.138088  0.866766   \n",
       "1           0006-aggregates.png  0.583940 -0.551095  0.573031 -0.542108   \n",
       "2  001-aggregates-jo_700_05.png -0.452301  0.901055 -0.440633  0.929559   \n",
       "3           0010-aggregates.png  0.553547 -0.551249  0.559949 -0.522796   \n",
       "4                      0011.png  0.878954 -1.234502  0.870033 -1.165677   \n",
       "\n",
       "         5         6         7         8         9   ...        87        88  \\\n",
       "0 -1.149040  0.865567 -1.170127  0.882358 -1.165774  ... -0.018641  0.365488   \n",
       "1  0.564279 -0.574851  0.556822 -0.644346  0.564660  ... -0.534824 -0.458842   \n",
       "2 -0.418416  0.959422 -0.391965  0.993847 -0.382175  ...  0.383506  1.067756   \n",
       "3  0.566758 -0.474370  0.565353 -0.468133  0.551870  ... -0.208128 -0.346751   \n",
       "4  0.867735 -1.162138  0.873726 -1.118144  0.914043  ... -0.775883 -1.183196   \n",
       "\n",
       "         89        90        91        92        93        94        95  \\\n",
       "0  0.462320  0.610102  0.639254  0.854176  0.087541  0.243078  0.794500   \n",
       "1 -0.467645 -0.587663 -0.184629 -0.352692  0.289746  0.295499  0.325833   \n",
       "2  0.131348  0.300736 -0.340842  0.092228 -0.424322  0.215652 -0.450190   \n",
       "3 -0.063954 -0.113626 -0.114338 -0.329164 -0.289741 -0.405385 -0.460871   \n",
       "4 -0.431509 -0.765326  0.178111 -0.425520 -0.282132 -0.658629 -0.743051   \n",
       "\n",
       "         96  \n",
       "0  0.856870  \n",
       "1  0.408612  \n",
       "2  0.159132  \n",
       "3 -0.544875  \n",
       "4 -1.142364  \n",
       "\n",
       "[5 rows x 97 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(14700, 97)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_gabor_validation_dff = pd.DataFrame(data = X_gabor_std_validation)\n",
    "X_gabor_validation_df = pd.DataFrame(data = dfFoldValidation_1[\"short_filenames\"])\n",
    "\n",
    "X_gabor_validation_df = pd.concat([X_gabor_validation_df,X_gabor_validation_dff], axis=1)\n",
    "X_gabor_validation_df.columns = pd.RangeIndex(X_gabor_validation_df.columns.size)\n",
    "\n",
    "display(X_gabor_validation_df.head(5), X_gabor_validation_df.shape)\n",
    "\n",
    "X_gabor_validation_df.to_csv(\"..//_inputs//_image_features//new//X-gabor_std_96_std-validation-fold_1.csv\", header=False, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2. For test set\n",
    "\n",
    "<u><b> Remarks :</b></u> We use 4-fold cross validaiton. Then, we need also to compute each kind of features for test set.\n",
    "So, for the test set, we extract 4 sets of features for each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTest = pd.read_csv('..//_inputs//_images_Zooscan//ZooScan-test_img.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4ad1cb1bd324b1594ade4200755768f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extract Gabor features:   0%|          | 0/6907 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filepaths = dfTest['filenames']\n",
    "\n",
    "n_files = len(filepaths)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "num_processes = 8\n",
    "\n",
    "gabor_test_list = []\n",
    "\n",
    "# i=0;\n",
    "with tqdm(total=n_files, desc=\"Extract Gabor features\") as pbar:\n",
    "\n",
    "    with Parallel(n_jobs=num_processes) as parallel:\n",
    "\n",
    "        for batch in chunked(image_generator(filepaths), batch_size):\n",
    "            \n",
    "            # i=i+1\n",
    "            # print('Working with batch: ',i)\n",
    "\n",
    "            batch_results = parallel(\n",
    "                delayed(extract_texture_features)(img) for img in batch)\n",
    "            \n",
    "            gabor_test_list.extend(batch_results)\n",
    "\n",
    "            del batch_results\n",
    "            gc.collect()\n",
    "\n",
    "            pbar.update(len(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard deviation normalization using above std_scale_train = preprocessing.StandardScaler().fit(gabor_test_list)\n",
    "X_gabor_std_test = std_scale_train.transform(gabor_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0007-aggregates_002.png</td>\n",
       "      <td>0.697323</td>\n",
       "      <td>-0.808015</td>\n",
       "      <td>0.695685</td>\n",
       "      <td>-0.813086</td>\n",
       "      <td>0.693752</td>\n",
       "      <td>-0.834384</td>\n",
       "      <td>0.683842</td>\n",
       "      <td>-0.861493</td>\n",
       "      <td>0.679107</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232577</td>\n",
       "      <td>-0.321633</td>\n",
       "      <td>-0.253101</td>\n",
       "      <td>-0.322692</td>\n",
       "      <td>-0.281572</td>\n",
       "      <td>-0.410231</td>\n",
       "      <td>-0.389857</td>\n",
       "      <td>-0.496872</td>\n",
       "      <td>-0.442787</td>\n",
       "      <td>-0.573586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0009-aggregates_001.png</td>\n",
       "      <td>1.071954</td>\n",
       "      <td>-1.023312</td>\n",
       "      <td>1.050105</td>\n",
       "      <td>-1.159215</td>\n",
       "      <td>1.029900</td>\n",
       "      <td>-1.328477</td>\n",
       "      <td>1.038799</td>\n",
       "      <td>-1.405424</td>\n",
       "      <td>1.051676</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.654648</td>\n",
       "      <td>-1.133130</td>\n",
       "      <td>-0.634690</td>\n",
       "      <td>-1.126482</td>\n",
       "      <td>-0.661392</td>\n",
       "      <td>-1.095521</td>\n",
       "      <td>-0.674366</td>\n",
       "      <td>-1.084152</td>\n",
       "      <td>-0.634005</td>\n",
       "      <td>-1.124700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0012-aggregates_002.png</td>\n",
       "      <td>1.178067</td>\n",
       "      <td>-1.612691</td>\n",
       "      <td>1.175463</td>\n",
       "      <td>-1.609940</td>\n",
       "      <td>1.168327</td>\n",
       "      <td>-1.605932</td>\n",
       "      <td>1.153877</td>\n",
       "      <td>-1.553238</td>\n",
       "      <td>1.146037</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.569331</td>\n",
       "      <td>-1.130898</td>\n",
       "      <td>-0.609587</td>\n",
       "      <td>-1.272601</td>\n",
       "      <td>-0.602741</td>\n",
       "      <td>-1.309572</td>\n",
       "      <td>-0.584470</td>\n",
       "      <td>-1.288972</td>\n",
       "      <td>-0.586553</td>\n",
       "      <td>-1.250737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002-aggregates_001.png</td>\n",
       "      <td>0.427048</td>\n",
       "      <td>-0.522704</td>\n",
       "      <td>0.205709</td>\n",
       "      <td>-0.306068</td>\n",
       "      <td>0.020965</td>\n",
       "      <td>-0.079924</td>\n",
       "      <td>-0.031241</td>\n",
       "      <td>-0.103162</td>\n",
       "      <td>-0.010247</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.046277</td>\n",
       "      <td>-0.396232</td>\n",
       "      <td>-0.878527</td>\n",
       "      <td>-0.259588</td>\n",
       "      <td>-0.606440</td>\n",
       "      <td>-0.084636</td>\n",
       "      <td>-0.335342</td>\n",
       "      <td>0.174256</td>\n",
       "      <td>-0.090707</td>\n",
       "      <td>0.027752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002-aggregates_007.png</td>\n",
       "      <td>-0.449403</td>\n",
       "      <td>1.010885</td>\n",
       "      <td>-0.441765</td>\n",
       "      <td>1.021145</td>\n",
       "      <td>-0.439187</td>\n",
       "      <td>1.020487</td>\n",
       "      <td>-0.447650</td>\n",
       "      <td>1.000680</td>\n",
       "      <td>-0.452431</td>\n",
       "      <td>...</td>\n",
       "      <td>1.371099</td>\n",
       "      <td>1.642061</td>\n",
       "      <td>0.863731</td>\n",
       "      <td>1.276360</td>\n",
       "      <td>0.259719</td>\n",
       "      <td>0.622112</td>\n",
       "      <td>-0.047238</td>\n",
       "      <td>0.272648</td>\n",
       "      <td>-0.308480</td>\n",
       "      <td>-0.130846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0         1         2         3         4         5   \\\n",
       "0  0007-aggregates_002.png  0.697323 -0.808015  0.695685 -0.813086  0.693752   \n",
       "1  0009-aggregates_001.png  1.071954 -1.023312  1.050105 -1.159215  1.029900   \n",
       "2  0012-aggregates_002.png  1.178067 -1.612691  1.175463 -1.609940  1.168327   \n",
       "3   002-aggregates_001.png  0.427048 -0.522704  0.205709 -0.306068  0.020965   \n",
       "4   002-aggregates_007.png -0.449403  1.010885 -0.441765  1.021145 -0.439187   \n",
       "\n",
       "         6         7         8         9   ...        87        88        89  \\\n",
       "0 -0.834384  0.683842 -0.861493  0.679107  ... -0.232577 -0.321633 -0.253101   \n",
       "1 -1.328477  1.038799 -1.405424  1.051676  ... -0.654648 -1.133130 -0.634690   \n",
       "2 -1.605932  1.153877 -1.553238  1.146037  ... -0.569331 -1.130898 -0.609587   \n",
       "3 -0.079924 -0.031241 -0.103162 -0.010247  ... -1.046277 -0.396232 -0.878527   \n",
       "4  1.020487 -0.447650  1.000680 -0.452431  ...  1.371099  1.642061  0.863731   \n",
       "\n",
       "         90        91        92        93        94        95        96  \n",
       "0 -0.322692 -0.281572 -0.410231 -0.389857 -0.496872 -0.442787 -0.573586  \n",
       "1 -1.126482 -0.661392 -1.095521 -0.674366 -1.084152 -0.634005 -1.124700  \n",
       "2 -1.272601 -0.602741 -1.309572 -0.584470 -1.288972 -0.586553 -1.250737  \n",
       "3 -0.259588 -0.606440 -0.084636 -0.335342  0.174256 -0.090707  0.027752  \n",
       "4  1.276360  0.259719  0.622112 -0.047238  0.272648 -0.308480 -0.130846  \n",
       "\n",
       "[5 rows x 97 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(6907, 97)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_gabor_test_dff = pd.DataFrame(data = X_gabor_std_test)\n",
    "X_gabor_test_df = pd.DataFrame(data = dfTest[\"short_filenames\"])\n",
    "\n",
    "X_gabor_test_df = pd.concat([X_gabor_test_df,X_gabor_test_dff], axis=1)\n",
    "X_gabor_test_df.columns = pd.RangeIndex(X_gabor_test_df.columns.size)\n",
    "\n",
    "display(X_gabor_test_df.head(5), X_gabor_test_df.shape)\n",
    "\n",
    "X_gabor_test_df.to_csv(\"..//_inputs//_image_features//new//X-gabor_96_std-test-fold_1.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "471"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del list_gabor_train2, list_gabor_train\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2000\n",
    "\n",
    "list_dfFoldTraining_1_chunked = [dfFoldTraining_1[i:i+n] for i in range(0, len(dfFoldTraining_1), n)]\n",
    "\n",
    "display(len(list_dfFoldTraining_1_chunked))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Parallel(n_jobs=2) as parallel:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gabor_list_train = None\n",
    "\n",
    "pbar = tqdm(list_dfFoldTraining_1_chunked)\n",
    "\n",
    "for i, dfFoldTraining_1_chunked in enumerate(pbar):\n",
    "    pbar.set_description(f'Processing the chunked data {i+1}')\n",
    "    \n",
    "    gabor_list_train_chunked = extract_gabor(dfFoldTraining_1_chunked)\n",
    "\n",
    "    gabor_list_train = np.vstack(gabor_list_train_chunked)\n",
    "\n",
    "    del  gabor_list_train_chunked\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a standard deviation normalization for later uses\n",
    "train_std_norm = StandardScaler().fit(HOG_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard deviation normalization\n",
    "HOG_list_std = train_std_norm.transform(HOG_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HOG_list_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total HOG features:',(HOG_list_std.shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Test the joblib with batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "from more_itertools import chunked\n",
    "\n",
    "def extract_gabor_from_filepath(img):\n",
    "    process = psutil.Process(mp.current_process().pid)\n",
    "    print(f\"Worker memory usage: {process.memory_info().rss / 1024 / 1024} MB\")\n",
    "        \n",
    "    # Create Gabor filter bank\n",
    "    fmax = 0.327 # maximum frequency\n",
    "    k = np.sqrt(2) #frequency ratio or factor for selecting filter frequencies\n",
    "    p = 0.5 # crossing point between two consecutive filters, default 0.5\n",
    "    u = 6 #number of frequencies\n",
    "    v = 8 #number of orientation\n",
    "    gamma = 0.5  #smoothting parameter \n",
    "    eta = 0.5  #smoothting parameter of\n",
    "    row = img.shape[0]\n",
    "    col = img.shape[1] # size of image\n",
    "\n",
    "    GaborFilterBank = gbb().create_a_set_of_gabor_filters(fmax, k, p, u, v, row, col, gamma, eta)\n",
    "    \n",
    "    # Filter with the filter bank\n",
    "    GaborFilteredReponses = gbfrb().create_a_set_of_Gabor_filtered_responses(img, GaborFilterBank)\n",
    "\n",
    "    # Convert responses to simple 3-D matrix with normalization\n",
    "    filteredImages = gbfrb().convert_a_set_Gabor_filtered_responses_to_ndarray(GaborFilteredReponses)\n",
    "    \n",
    "    # Get mean and standard deviation of each response as Gabor (texture) features of an input image\n",
    "    nImages = filteredImages.shape[2]\n",
    "    textureFeatures = np.zeros(nImages*2)\n",
    "\n",
    "    index=0\n",
    "    for i in range(0, nImages):\n",
    "        textureFeatures[index] = np.mean(np.abs(filteredImages[:,:,i]));\n",
    "        index = index + 1;\n",
    "        textureFeatures[index] = np.std(np.abs(filteredImages[:,:,i]));\n",
    "        index = index + 1;\n",
    "    \n",
    "    return textureFeatures\n",
    "\n",
    "def image_generator(filepaths):\n",
    "    for filepath in filepaths:\n",
    "        yield io.imread(filepath, as_gray=True)\n",
    "\n",
    "\n",
    "# def extract_texture_features(img):\n",
    "#     process = psutil.Process(mp.current_process().pid)\n",
    "#     print(f\"Worker memory usage: {process.memory_info().rss / 1024 / 1024} MB\")\n",
    "#     # your existing code here\n",
    "#     textureFeatures = extract_gabor_from_filepath(img)\n",
    "#     return textureFeatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = dfFoldTraining_1['filenames']\n",
    "batch_size = 100\n",
    "chunk_size = 400\n",
    "num_processes = mp.cpu_count()-4\n",
    "results = []\n",
    "with Parallel(n_jobs=num_processes) as parallel:\n",
    "    for batch in tqdm(chunked(image_generator(filepaths), batch_size), total=len(filepaths)//batch_size):\n",
    "        \n",
    "        batch_results = parallel(\n",
    "            delayed(extract_gabor_from_filepath)(img) for img in batch)\n",
    "        \n",
    "        results.extend(batch_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Test with multipleprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "from more_itertools import chunked\n",
    "\n",
    "from skimage.filters import threshold_niblack\n",
    "from skimage.morphology import convex_hull_image\n",
    "from skimage.measure import find_contours\n",
    "\n",
    "def crop_image(image):\n",
    "    img_height = image.shape[0]\n",
    "    if img_height < 2000:\n",
    "        return image\n",
    "    \n",
    "    # adaptive thresholding\n",
    "    thresh_niblack = threshold_niblack(image, window_size=25, k=0.8)\n",
    "    binary_niblack = image > thresh_niblack\n",
    "\n",
    "    # make convex hull\n",
    "    chull = convex_hull_image(np.pad(binary_niblack, 3, 'constant', constant_values=0))\n",
    "    \n",
    "    # Find the contours of the main object\n",
    "    contours = find_contours(chull, 0.5)\n",
    "\n",
    "    # Find the largest contour (assumed to be the main object)\n",
    "    largest_contour = max(contours, key=len)\n",
    "\n",
    "    # Compute the bounding box coordinates for the largest contour\n",
    "    min_row, min_col = np.min(largest_contour, axis=0)\n",
    "    max_row, max_col = np.max(largest_contour, axis=0)\n",
    "\n",
    "    # Compute the optimal cropping dimensions based on the bounding box\n",
    "    padding = 10  # Adjust the padding as desired\n",
    "    crop_min_row = int(max(min_row - padding, 0))\n",
    "    crop_min_col = int(max(min_col - padding, 0))\n",
    "    crop_max_row = int(min(max_row + padding, image.shape[0]))\n",
    "    crop_max_col = int(min(max_col + padding, image.shape[1]))\n",
    "\n",
    "    # Crop the image using the computed dimensions\n",
    "    cropped_image = image[crop_min_row:crop_max_row, crop_min_col:crop_max_col]\n",
    "\n",
    "    return cropped_image\n",
    "\n",
    "\n",
    "def image_generator(filepaths):\n",
    "    for filepath in filepaths:\n",
    "        yield io.imread(filepath, as_gray=True)\n",
    "\n",
    "def extract_texture_features(image): \n",
    "\n",
    "    img = crop_image(image)\n",
    "\n",
    "    # Create Gabor filter bank\n",
    "    fmax = 0.327 # maximum frequency\n",
    "    k = np.sqrt(2) #frequency ratio or factor for selecting filter frequencies\n",
    "    p = 0.5 # crossing point between two consecutive filters, default 0.5\n",
    "    u = 6 #number of frequencies\n",
    "    v = 8 #number of orientation\n",
    "    gamma = 0.5  #smoothting parameter \n",
    "    eta = 0.5  #smoothting parameter of\n",
    "    row = img.shape[0]\n",
    "    col = img.shape[1] # size of image\n",
    "\n",
    "    GaborFilterBank = gbb().create_a_set_of_gabor_filters(fmax, k, p, u, v, row, col, gamma, eta)\n",
    "    \n",
    "    # Filter with the filter bank\n",
    "    GaborFilteredReponses = gbfrb().create_a_set_of_Gabor_filtered_responses(img, GaborFilterBank)\n",
    "\n",
    "    # Convert responses to simple 3-D matrix with normalization\n",
    "    filteredImages = gbfrb().convert_a_set_Gabor_filtered_responses_to_ndarray(GaborFilteredReponses)\n",
    "    \n",
    "    # Get mean and standard deviation of each response as Gabor (texture) features of an input image\n",
    "    nImages = filteredImages.shape[2]\n",
    "    textureFeatures = np.zeros(nImages*2)\n",
    "\n",
    "    index=0\n",
    "    for i in range(0, nImages):\n",
    "        textureFeatures[index] = np.mean(np.abs(filteredImages[:,:,i]));\n",
    "        index = index + 1;\n",
    "        textureFeatures[index] = np.std(np.abs(filteredImages[:,:,i]));\n",
    "        index = index + 1;\n",
    "    \n",
    "    return textureFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = dfFoldTraining_1['filenames']\n",
    "\n",
    "n_files = len(filepaths)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "num_processes = 4\n",
    "\n",
    "results = []\n",
    "\n",
    "chunk_size = 64\n",
    "\n",
    "num_processes = mp.cpu_count() - 10 # number of workers\n",
    "\n",
    "i=0;\n",
    "with tqdm(total=n_files, desc=\"Extract Gabor features\") as pbar:\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    with mp.Pool(processes=num_processes) as pool:\n",
    "\n",
    "        for batch in chunked(image_generator(filepaths), batch_size):\n",
    "            \n",
    "            batch_results = list(pool.imap(extract_texture_features, batch, chunksize=chunk_size))\n",
    "            \n",
    "            results.extend(batch_results)\n",
    "\n",
    "            del batch_results\n",
    "\n",
    "            gc.collect()\n",
    "\n",
    "            pbar.update(len(batch))\n",
    "\n",
    "        # pool.close()\n",
    "        # pool.join()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Test with joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "from more_itertools import chunked\n",
    "\n",
    "from skimage.filters import threshold_niblack\n",
    "from skimage.morphology import convex_hull_image\n",
    "from skimage.measure import find_contours\n",
    "\n",
    "def crop_image(image):\n",
    "    img_height = image.shape[0]\n",
    "    if img_height < 2000:\n",
    "        return image\n",
    "    \n",
    "    # adaptive thresholding\n",
    "    thresh_niblack = threshold_niblack(image, window_size=25, k=0.8)\n",
    "    binary_niblack = image > thresh_niblack\n",
    "\n",
    "    # make convex hull\n",
    "    chull = convex_hull_image(np.pad(binary_niblack, 3, 'constant', constant_values=0))\n",
    "    \n",
    "    # Find the contours of the main object\n",
    "    contours = find_contours(chull, 0.5)\n",
    "\n",
    "    # Find the largest contour (assumed to be the main object)\n",
    "    largest_contour = max(contours, key=len)\n",
    "\n",
    "    # Compute the bounding box coordinates for the largest contour\n",
    "    min_row, min_col = np.min(largest_contour, axis=0)\n",
    "    max_row, max_col = np.max(largest_contour, axis=0)\n",
    "\n",
    "    # Compute the optimal cropping dimensions based on the bounding box\n",
    "    padding = 10  # Adjust the padding as desired\n",
    "    crop_min_row = int(max(min_row - padding, 0))\n",
    "    crop_min_col = int(max(min_col - padding, 0))\n",
    "    crop_max_row = int(min(max_row + padding, image.shape[0]))\n",
    "    crop_max_col = int(min(max_col + padding, image.shape[1]))\n",
    "\n",
    "    # Crop the image using the computed dimensions\n",
    "    cropped_image = image[crop_min_row:crop_max_row, crop_min_col:crop_max_col]\n",
    "\n",
    "    return cropped_image\n",
    "\n",
    "def image_generator(filepaths):\n",
    "    for filepath in filepaths:\n",
    "        yield io.imread(filepath, as_gray=True)\n",
    "\n",
    "def extract_texture_features(image):   \n",
    "    img = crop_image(image) \n",
    "    # Create Gabor filter bank\n",
    "    fmax = 0.327 # maximum frequency\n",
    "    k = np.sqrt(2) #frequency ratio or factor for selecting filter frequencies\n",
    "    p = 0.5 # crossing point between two consecutive filters, default 0.5\n",
    "    u = 6 #number of frequencies\n",
    "    v = 8 #number of orientation\n",
    "    gamma = 0.5  #smoothting parameter \n",
    "    eta = 0.5  #smoothting parameter of\n",
    "    row = img.shape[0]\n",
    "    col = img.shape[1] # size of image\n",
    "\n",
    "    GaborFilterBank = gbb().create_a_set_of_gabor_filters(fmax, k, p, u, v, row, col, gamma, eta)\n",
    "    \n",
    "    # Filter with the filter bank\n",
    "    GaborFilteredReponses = gbfrb().create_a_set_of_Gabor_filtered_responses(img, GaborFilterBank)\n",
    "\n",
    "    # Convert responses to simple 3-D matrix with normalization\n",
    "    filteredImages = gbfrb().convert_a_set_Gabor_filtered_responses_to_ndarray(GaborFilteredReponses)\n",
    "    \n",
    "    # Get mean and standard deviation of each response as Gabor (texture) features of an input image\n",
    "    nImages = filteredImages.shape[2]\n",
    "    textureFeatures = np.zeros(nImages*2)\n",
    "\n",
    "    index=0\n",
    "    for i in range(0, nImages):\n",
    "        textureFeatures[index] = np.mean(np.abs(filteredImages[:,:,i]));\n",
    "        index = index + 1;\n",
    "        textureFeatures[index] = np.std(np.abs(filteredImages[:,:,i]));\n",
    "        index = index + 1;\n",
    "    \n",
    "    del filteredImages, GaborFilteredReponses, GaborFilterBank\n",
    "    gc.collect()\n",
    "    \n",
    "    return textureFeatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79a575b572154477bb73e7693f38d647",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extract Gabor features:   0%|          | 0/44099 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with batch:  1\n",
      "Working with batch:  2\n",
      "Working with batch:  3\n",
      "Working with batch:  4\n",
      "Working with batch:  5\n",
      "Working with batch:  6\n",
      "Working with batch:  7\n",
      "Working with batch:  8\n",
      "Working with batch:  9\n",
      "Working with batch:  10\n",
      "Working with batch:  11\n",
      "Working with batch:  12\n",
      "Working with batch:  13\n",
      "Working with batch:  14\n",
      "Working with batch:  15\n",
      "Working with batch:  16\n",
      "Working with batch:  17\n",
      "Working with batch:  18\n",
      "Working with batch:  19\n",
      "Working with batch:  20\n",
      "Working with batch:  21\n",
      "Working with batch:  22\n",
      "Working with batch:  23\n",
      "Working with batch:  24\n",
      "Working with batch:  25\n",
      "Working with batch:  26\n",
      "Working with batch:  27\n",
      "Working with batch:  28\n",
      "Working with batch:  29\n",
      "Working with batch:  30\n",
      "Working with batch:  31\n",
      "Working with batch:  32\n",
      "Working with batch:  33\n",
      "Working with batch:  34\n",
      "Working with batch:  35\n",
      "Working with batch:  36\n",
      "Working with batch:  37\n",
      "Working with batch:  38\n",
      "Working with batch:  39\n",
      "Working with batch:  40\n",
      "Working with batch:  41\n",
      "Working with batch:  42\n",
      "Working with batch:  43\n",
      "Working with batch:  44\n",
      "Working with batch:  45\n",
      "Working with batch:  46\n",
      "Working with batch:  47\n",
      "Working with batch:  48\n",
      "Working with batch:  49\n",
      "Working with batch:  50\n",
      "Working with batch:  51\n",
      "Working with batch:  52\n",
      "Working with batch:  53\n",
      "Working with batch:  54\n",
      "Working with batch:  55\n",
      "Working with batch:  56\n",
      "Working with batch:  57\n",
      "Working with batch:  58\n",
      "Working with batch:  59\n",
      "Working with batch:  60\n",
      "Working with batch:  61\n",
      "Working with batch:  62\n",
      "Working with batch:  63\n",
      "Working with batch:  64\n",
      "Working with batch:  65\n",
      "Working with batch:  66\n",
      "Working with batch:  67\n",
      "Working with batch:  68\n",
      "Working with batch:  69\n",
      "Working with batch:  70\n",
      "Working with batch:  71\n",
      "Working with batch:  72\n",
      "Working with batch:  73\n",
      "Working with batch:  74\n",
      "Working with batch:  75\n",
      "Working with batch:  76\n",
      "Working with batch:  77\n",
      "Working with batch:  78\n",
      "Working with batch:  79\n",
      "Working with batch:  80\n",
      "Working with batch:  81\n",
      "Working with batch:  82\n",
      "Working with batch:  83\n",
      "Working with batch:  84\n",
      "Working with batch:  85\n",
      "Working with batch:  86\n",
      "Working with batch:  87\n",
      "Working with batch:  88\n",
      "Working with batch:  89\n",
      "Working with batch:  90\n",
      "Working with batch:  91\n",
      "Working with batch:  92\n",
      "Working with batch:  93\n",
      "Working with batch:  94\n",
      "Working with batch:  95\n",
      "Working with batch:  96\n",
      "Working with batch:  97\n",
      "Working with batch:  98\n",
      "Working with batch:  99\n",
      "Working with batch:  100\n",
      "Working with batch:  101\n",
      "Working with batch:  102\n",
      "Working with batch:  103\n",
      "Working with batch:  104\n",
      "Working with batch:  105\n",
      "Working with batch:  106\n",
      "Working with batch:  107\n",
      "Working with batch:  108\n",
      "Working with batch:  109\n",
      "Working with batch:  110\n",
      "Working with batch:  111\n",
      "Working with batch:  112\n",
      "Working with batch:  113\n",
      "Working with batch:  114\n",
      "Working with batch:  115\n",
      "Working with batch:  116\n",
      "Working with batch:  117\n",
      "Working with batch:  118\n",
      "Working with batch:  119\n",
      "Working with batch:  120\n",
      "Working with batch:  121\n",
      "Working with batch:  122\n",
      "Working with batch:  123\n",
      "Working with batch:  124\n",
      "Working with batch:  125\n",
      "Working with batch:  126\n",
      "Working with batch:  127\n",
      "Working with batch:  128\n",
      "Working with batch:  129\n",
      "Working with batch:  130\n",
      "Working with batch:  131\n",
      "Working with batch:  132\n",
      "Working with batch:  133\n",
      "Working with batch:  134\n",
      "Working with batch:  135\n",
      "Working with batch:  136\n",
      "Working with batch:  137\n",
      "Working with batch:  138\n",
      "Working with batch:  139\n",
      "Working with batch:  140\n",
      "Working with batch:  141\n",
      "Working with batch:  142\n",
      "Working with batch:  143\n",
      "Working with batch:  144\n",
      "Working with batch:  145\n",
      "Working with batch:  146\n",
      "Working with batch:  147\n",
      "Working with batch:  148\n",
      "Working with batch:  149\n",
      "Working with batch:  150\n",
      "Working with batch:  151\n",
      "Working with batch:  152\n",
      "Working with batch:  153\n",
      "Working with batch:  154\n",
      "Working with batch:  155\n",
      "Working with batch:  156\n",
      "Working with batch:  157\n",
      "Working with batch:  158\n",
      "Working with batch:  159\n",
      "Working with batch:  160\n",
      "Working with batch:  161\n",
      "Working with batch:  162\n",
      "Working with batch:  163\n",
      "Working with batch:  164\n",
      "Working with batch:  165\n",
      "Working with batch:  166\n",
      "Working with batch:  167\n",
      "Working with batch:  168\n",
      "Working with batch:  169\n",
      "Working with batch:  170\n",
      "Working with batch:  171\n",
      "Working with batch:  172\n",
      "Working with batch:  173\n",
      "Working with batch:  174\n",
      "Working with batch:  175\n",
      "Working with batch:  176\n",
      "Working with batch:  177\n",
      "Working with batch:  178\n",
      "Working with batch:  179\n",
      "Working with batch:  180\n",
      "Working with batch:  181\n",
      "Working with batch:  182\n",
      "Working with batch:  183\n",
      "Working with batch:  184\n",
      "Working with batch:  185\n",
      "Working with batch:  186\n",
      "Working with batch:  187\n",
      "Working with batch:  188\n",
      "Working with batch:  189\n",
      "Working with batch:  190\n",
      "Working with batch:  191\n",
      "Working with batch:  192\n",
      "Working with batch:  193\n",
      "Working with batch:  194\n",
      "Working with batch:  195\n",
      "Working with batch:  196\n",
      "Working with batch:  197\n",
      "Working with batch:  198\n",
      "Working with batch:  199\n",
      "Working with batch:  200\n",
      "Working with batch:  201\n",
      "Working with batch:  202\n",
      "Working with batch:  203\n",
      "Working with batch:  204\n",
      "Working with batch:  205\n",
      "Working with batch:  206\n",
      "Working with batch:  207\n",
      "Working with batch:  208\n",
      "Working with batch:  209\n",
      "Working with batch:  210\n",
      "Working with batch:  211\n",
      "Working with batch:  212\n",
      "Working with batch:  213\n",
      "Working with batch:  214\n",
      "Working with batch:  215\n",
      "Working with batch:  216\n",
      "Working with batch:  217\n",
      "Working with batch:  218\n",
      "Working with batch:  219\n",
      "Working with batch:  220\n",
      "Working with batch:  221\n",
      "Working with batch:  222\n",
      "Working with batch:  223\n",
      "Working with batch:  224\n",
      "Working with batch:  225\n",
      "Working with batch:  226\n",
      "Working with batch:  227\n",
      "Working with batch:  228\n",
      "Working with batch:  229\n",
      "Working with batch:  230\n",
      "Working with batch:  231\n",
      "Working with batch:  232\n",
      "Working with batch:  233\n",
      "Working with batch:  234\n",
      "Working with batch:  235\n",
      "Working with batch:  236\n",
      "Working with batch:  237\n",
      "Working with batch:  238\n",
      "Working with batch:  239\n",
      "Working with batch:  240\n",
      "Working with batch:  241\n",
      "Working with batch:  242\n",
      "Working with batch:  243\n",
      "Working with batch:  244\n",
      "Working with batch:  245\n",
      "Working with batch:  246\n",
      "Working with batch:  247\n",
      "Working with batch:  248\n",
      "Working with batch:  249\n",
      "Working with batch:  250\n",
      "Working with batch:  251\n",
      "Working with batch:  252\n",
      "Working with batch:  253\n",
      "Working with batch:  254\n",
      "Working with batch:  255\n",
      "Working with batch:  256\n",
      "Working with batch:  257\n",
      "Working with batch:  258\n",
      "Working with batch:  259\n",
      "Working with batch:  260\n",
      "Working with batch:  261\n",
      "Working with batch:  262\n",
      "Working with batch:  263\n",
      "Working with batch:  264\n",
      "Working with batch:  265\n",
      "Working with batch:  266\n",
      "Working with batch:  267\n",
      "Working with batch:  268\n",
      "Working with batch:  269\n",
      "Working with batch:  270\n",
      "Working with batch:  271\n",
      "Working with batch:  272\n",
      "Working with batch:  273\n",
      "Working with batch:  274\n",
      "Working with batch:  275\n",
      "Working with batch:  276\n",
      "Working with batch:  277\n",
      "Working with batch:  278\n",
      "Working with batch:  279\n",
      "Working with batch:  280\n",
      "Working with batch:  281\n",
      "Working with batch:  282\n",
      "Working with batch:  283\n",
      "Working with batch:  284\n",
      "Working with batch:  285\n",
      "Working with batch:  286\n",
      "Working with batch:  287\n",
      "Working with batch:  288\n",
      "Working with batch:  289\n",
      "Working with batch:  290\n",
      "Working with batch:  291\n",
      "Working with batch:  292\n",
      "Working with batch:  293\n",
      "Working with batch:  294\n",
      "Working with batch:  295\n",
      "Working with batch:  296\n",
      "Working with batch:  297\n",
      "Working with batch:  298\n",
      "Working with batch:  299\n",
      "Working with batch:  300\n",
      "Working with batch:  301\n",
      "Working with batch:  302\n",
      "Working with batch:  303\n",
      "Working with batch:  304\n",
      "Working with batch:  305\n",
      "Working with batch:  306\n",
      "Working with batch:  307\n",
      "Working with batch:  308\n",
      "Working with batch:  309\n",
      "Working with batch:  310\n",
      "Working with batch:  311\n",
      "Working with batch:  312\n",
      "Working with batch:  313\n",
      "Working with batch:  314\n",
      "Working with batch:  315\n",
      "Working with batch:  316\n",
      "Working with batch:  317\n",
      "Working with batch:  318\n",
      "Working with batch:  319\n",
      "Working with batch:  320\n",
      "Working with batch:  321\n",
      "Working with batch:  322\n",
      "Working with batch:  323\n",
      "Working with batch:  324\n",
      "Working with batch:  325\n",
      "Working with batch:  326\n",
      "Working with batch:  327\n",
      "Working with batch:  328\n",
      "Working with batch:  329\n",
      "Working with batch:  330\n",
      "Working with batch:  331\n",
      "Working with batch:  332\n",
      "Working with batch:  333\n",
      "Working with batch:  334\n",
      "Working with batch:  335\n",
      "Working with batch:  336\n",
      "Working with batch:  337\n",
      "Working with batch:  338\n",
      "Working with batch:  339\n",
      "Working with batch:  340\n",
      "Working with batch:  341\n",
      "Working with batch:  342\n",
      "Working with batch:  343\n",
      "Working with batch:  344\n",
      "Working with batch:  345\n",
      "Working with batch:  346\n",
      "Working with batch:  347\n",
      "Working with batch:  348\n",
      "Working with batch:  349\n",
      "Working with batch:  350\n",
      "Working with batch:  351\n",
      "Working with batch:  352\n",
      "Working with batch:  353\n",
      "Working with batch:  354\n",
      "Working with batch:  355\n",
      "Working with batch:  356\n",
      "Working with batch:  357\n",
      "Working with batch:  358\n",
      "Working with batch:  359\n",
      "Working with batch:  360\n",
      "Working with batch:  361\n",
      "Working with batch:  362\n",
      "Working with batch:  363\n",
      "Working with batch:  364\n",
      "Working with batch:  365\n",
      "Working with batch:  366\n",
      "Working with batch:  367\n",
      "Working with batch:  368\n",
      "Working with batch:  369\n",
      "Working with batch:  370\n",
      "Working with batch:  371\n",
      "Working with batch:  372\n",
      "Working with batch:  373\n",
      "Working with batch:  374\n",
      "Working with batch:  375\n",
      "Working with batch:  376\n",
      "Working with batch:  377\n",
      "Working with batch:  378\n",
      "Working with batch:  379\n",
      "Working with batch:  380\n",
      "Working with batch:  381\n",
      "Working with batch:  382\n",
      "Working with batch:  383\n",
      "Working with batch:  384\n",
      "Working with batch:  385\n",
      "Working with batch:  386\n",
      "Working with batch:  387\n",
      "Working with batch:  388\n",
      "Working with batch:  389\n",
      "Working with batch:  390\n",
      "Working with batch:  391\n",
      "Working with batch:  392\n",
      "Working with batch:  393\n",
      "Working with batch:  394\n",
      "Working with batch:  395\n",
      "Working with batch:  396\n",
      "Working with batch:  397\n",
      "Working with batch:  398\n",
      "Working with batch:  399\n",
      "Working with batch:  400\n",
      "Working with batch:  401\n",
      "Working with batch:  402\n",
      "Working with batch:  403\n",
      "Working with batch:  404\n",
      "Working with batch:  405\n",
      "Working with batch:  406\n",
      "Working with batch:  407\n",
      "Working with batch:  408\n",
      "Working with batch:  409\n",
      "Working with batch:  410\n",
      "Working with batch:  411\n",
      "Working with batch:  412\n",
      "Working with batch:  413\n",
      "Working with batch:  414\n",
      "Working with batch:  415\n",
      "Working with batch:  416\n",
      "Working with batch:  417\n",
      "Working with batch:  418\n",
      "Working with batch:  419\n",
      "Working with batch:  420\n",
      "Working with batch:  421\n",
      "Working with batch:  422\n",
      "Working with batch:  423\n",
      "Working with batch:  424\n",
      "Working with batch:  425\n",
      "Working with batch:  426\n",
      "Working with batch:  427\n",
      "Working with batch:  428\n",
      "Working with batch:  429\n",
      "Working with batch:  430\n",
      "Working with batch:  431\n",
      "Working with batch:  432\n",
      "Working with batch:  433\n",
      "Working with batch:  434\n",
      "Working with batch:  435\n",
      "Working with batch:  436\n",
      "Working with batch:  437\n",
      "Working with batch:  438\n",
      "Working with batch:  439\n",
      "Working with batch:  440\n",
      "Working with batch:  441\n",
      "Working with batch:  442\n",
      "Working with batch:  443\n",
      "Working with batch:  444\n",
      "Working with batch:  445\n",
      "Working with batch:  446\n",
      "Working with batch:  447\n",
      "Working with batch:  448\n",
      "Working with batch:  449\n",
      "Working with batch:  450\n",
      "Working with batch:  451\n",
      "Working with batch:  452\n",
      "Working with batch:  453\n",
      "Working with batch:  454\n",
      "Working with batch:  455\n",
      "Working with batch:  456\n",
      "Working with batch:  457\n",
      "Working with batch:  458\n",
      "Working with batch:  459\n",
      "Working with batch:  460\n",
      "Working with batch:  461\n",
      "Working with batch:  462\n",
      "Working with batch:  463\n",
      "Working with batch:  464\n",
      "Working with batch:  465\n",
      "Working with batch:  466\n",
      "Working with batch:  467\n",
      "Working with batch:  468\n",
      "Working with batch:  469\n",
      "Working with batch:  470\n",
      "Working with batch:  471\n",
      "Working with batch:  472\n",
      "Working with batch:  473\n",
      "Working with batch:  474\n",
      "Working with batch:  475\n",
      "Working with batch:  476\n",
      "Working with batch:  477\n",
      "Working with batch:  478\n",
      "Working with batch:  479\n",
      "Working with batch:  480\n",
      "Working with batch:  481\n",
      "Working with batch:  482\n",
      "Working with batch:  483\n",
      "Working with batch:  484\n",
      "Working with batch:  485\n",
      "Working with batch:  486\n",
      "Working with batch:  487\n",
      "Working with batch:  488\n",
      "Working with batch:  489\n",
      "Working with batch:  490\n",
      "Working with batch:  491\n",
      "Working with batch:  492\n",
      "Working with batch:  493\n",
      "Working with batch:  494\n",
      "Working with batch:  495\n",
      "Working with batch:  496\n",
      "Working with batch:  497\n",
      "Working with batch:  498\n",
      "Working with batch:  499\n",
      "Working with batch:  500\n",
      "Working with batch:  501\n",
      "Working with batch:  502\n",
      "Working with batch:  503\n",
      "Working with batch:  504\n",
      "Working with batch:  505\n",
      "Working with batch:  506\n",
      "Working with batch:  507\n",
      "Working with batch:  508\n",
      "Working with batch:  509\n",
      "Working with batch:  510\n",
      "Working with batch:  511\n",
      "Working with batch:  512\n",
      "Working with batch:  513\n",
      "Working with batch:  514\n",
      "Working with batch:  515\n",
      "Working with batch:  516\n",
      "Working with batch:  517\n",
      "Working with batch:  518\n",
      "Working with batch:  519\n",
      "Working with batch:  520\n",
      "Working with batch:  521\n",
      "Working with batch:  522\n",
      "Working with batch:  523\n",
      "Working with batch:  524\n",
      "Working with batch:  525\n",
      "Working with batch:  526\n",
      "Working with batch:  527\n",
      "Working with batch:  528\n",
      "Working with batch:  529\n",
      "Working with batch:  530\n",
      "Working with batch:  531\n",
      "Working with batch:  532\n",
      "Working with batch:  533\n",
      "Working with batch:  534\n",
      "Working with batch:  535\n",
      "Working with batch:  536\n",
      "Working with batch:  537\n",
      "Working with batch:  538\n",
      "Working with batch:  539\n",
      "Working with batch:  540\n",
      "Working with batch:  541\n",
      "Working with batch:  542\n",
      "Working with batch:  543\n",
      "Working with batch:  544\n",
      "Working with batch:  545\n",
      "Working with batch:  546\n",
      "Working with batch:  547\n",
      "Working with batch:  548\n",
      "Working with batch:  549\n",
      "Working with batch:  550\n",
      "Working with batch:  551\n",
      "Working with batch:  552\n",
      "Working with batch:  553\n",
      "Working with batch:  554\n",
      "Working with batch:  555\n",
      "Working with batch:  556\n",
      "Working with batch:  557\n",
      "Working with batch:  558\n",
      "Working with batch:  559\n",
      "Working with batch:  560\n",
      "Working with batch:  561\n",
      "Working with batch:  562\n",
      "Working with batch:  563\n",
      "Working with batch:  564\n",
      "Working with batch:  565\n",
      "Working with batch:  566\n",
      "Working with batch:  567\n",
      "Working with batch:  568\n",
      "Working with batch:  569\n",
      "Working with batch:  570\n",
      "Working with batch:  571\n",
      "Working with batch:  572\n",
      "Working with batch:  573\n",
      "Working with batch:  574\n",
      "Working with batch:  575\n",
      "Working with batch:  576\n",
      "Working with batch:  577\n",
      "Working with batch:  578\n",
      "Working with batch:  579\n",
      "Working with batch:  580\n",
      "Working with batch:  581\n",
      "Working with batch:  582\n",
      "Working with batch:  583\n",
      "Working with batch:  584\n",
      "Working with batch:  585\n",
      "Working with batch:  586\n",
      "Working with batch:  587\n",
      "Working with batch:  588\n",
      "Working with batch:  589\n",
      "Working with batch:  590\n",
      "Working with batch:  591\n",
      "Working with batch:  592\n",
      "Working with batch:  593\n",
      "Working with batch:  594\n",
      "Working with batch:  595\n",
      "Working with batch:  596\n",
      "Working with batch:  597\n",
      "Working with batch:  598\n",
      "Working with batch:  599\n",
      "Working with batch:  600\n",
      "Working with batch:  601\n",
      "Working with batch:  602\n",
      "Working with batch:  603\n",
      "Working with batch:  604\n",
      "Working with batch:  605\n",
      "Working with batch:  606\n",
      "Working with batch:  607\n",
      "Working with batch:  608\n",
      "Working with batch:  609\n",
      "Working with batch:  610\n",
      "Working with batch:  611\n",
      "Working with batch:  612\n",
      "Working with batch:  613\n",
      "Working with batch:  614\n",
      "Working with batch:  615\n",
      "Working with batch:  616\n",
      "Working with batch:  617\n",
      "Working with batch:  618\n",
      "Working with batch:  619\n",
      "Working with batch:  620\n",
      "Working with batch:  621\n",
      "Working with batch:  622\n",
      "Working with batch:  623\n",
      "Working with batch:  624\n",
      "Working with batch:  625\n",
      "Working with batch:  626\n",
      "Working with batch:  627\n",
      "Working with batch:  628\n",
      "Working with batch:  629\n",
      "Working with batch:  630\n",
      "Working with batch:  631\n",
      "Working with batch:  632\n",
      "Working with batch:  633\n",
      "Working with batch:  634\n",
      "Working with batch:  635\n",
      "Working with batch:  636\n",
      "Working with batch:  637\n",
      "Working with batch:  638\n",
      "Working with batch:  639\n",
      "Working with batch:  640\n",
      "Working with batch:  641\n",
      "Working with batch:  642\n",
      "Working with batch:  643\n",
      "Working with batch:  644\n",
      "Working with batch:  645\n",
      "Working with batch:  646\n",
      "Working with batch:  647\n",
      "Working with batch:  648\n",
      "Working with batch:  649\n",
      "Working with batch:  650\n",
      "Working with batch:  651\n",
      "Working with batch:  652\n",
      "Working with batch:  653\n",
      "Working with batch:  654\n",
      "Working with batch:  655\n",
      "Working with batch:  656\n",
      "Working with batch:  657\n",
      "Working with batch:  658\n",
      "Working with batch:  659\n",
      "Working with batch:  660\n",
      "Working with batch:  661\n",
      "Working with batch:  662\n",
      "Working with batch:  663\n",
      "Working with batch:  664\n",
      "Working with batch:  665\n",
      "Working with batch:  666\n",
      "Working with batch:  667\n",
      "Working with batch:  668\n",
      "Working with batch:  669\n",
      "Working with batch:  670\n",
      "Working with batch:  671\n",
      "Working with batch:  672\n",
      "Working with batch:  673\n",
      "Working with batch:  674\n",
      "Working with batch:  675\n",
      "Working with batch:  676\n",
      "Working with batch:  677\n",
      "Working with batch:  678\n",
      "Working with batch:  679\n",
      "Working with batch:  680\n",
      "Working with batch:  681\n",
      "Working with batch:  682\n",
      "Working with batch:  683\n",
      "Working with batch:  684\n",
      "Working with batch:  685\n",
      "Working with batch:  686\n",
      "Working with batch:  687\n",
      "Working with batch:  688\n",
      "Working with batch:  689\n",
      "Working with batch:  690\n",
      "Working with batch:  691\n",
      "Working with batch:  692\n",
      "Working with batch:  693\n",
      "Working with batch:  694\n",
      "Working with batch:  695\n",
      "Working with batch:  696\n",
      "Working with batch:  697\n",
      "Working with batch:  698\n",
      "Working with batch:  699\n",
      "Working with batch:  700\n",
      "Working with batch:  701\n",
      "Working with batch:  702\n",
      "Working with batch:  703\n",
      "Working with batch:  704\n",
      "Working with batch:  705\n",
      "Working with batch:  706\n",
      "Working with batch:  707\n",
      "Working with batch:  708\n",
      "Working with batch:  709\n",
      "Working with batch:  710\n",
      "Working with batch:  711\n",
      "Working with batch:  712\n",
      "Working with batch:  713\n",
      "Working with batch:  714\n",
      "Working with batch:  715\n",
      "Working with batch:  716\n",
      "Working with batch:  717\n",
      "Working with batch:  718\n",
      "Working with batch:  719\n",
      "Working with batch:  720\n",
      "Working with batch:  721\n",
      "Working with batch:  722\n",
      "Working with batch:  723\n",
      "Working with batch:  724\n",
      "Working with batch:  725\n",
      "Working with batch:  726\n",
      "Working with batch:  727\n",
      "Working with batch:  728\n",
      "Working with batch:  729\n",
      "Working with batch:  730\n",
      "Working with batch:  731\n",
      "Working with batch:  732\n",
      "Working with batch:  733\n",
      "Working with batch:  734\n",
      "Working with batch:  735\n",
      "Working with batch:  736\n",
      "Working with batch:  737\n",
      "Working with batch:  738\n",
      "Working with batch:  739\n",
      "Working with batch:  740\n",
      "Working with batch:  741\n",
      "Working with batch:  742\n",
      "Working with batch:  743\n",
      "Working with batch:  744\n",
      "Working with batch:  745\n",
      "Working with batch:  746\n",
      "Working with batch:  747\n",
      "Working with batch:  748\n",
      "Working with batch:  749\n",
      "Working with batch:  750\n",
      "Working with batch:  751\n",
      "Working with batch:  752\n",
      "Working with batch:  753\n",
      "Working with batch:  754\n",
      "Working with batch:  755\n",
      "Working with batch:  756\n",
      "Working with batch:  757\n",
      "Working with batch:  758\n",
      "Working with batch:  759\n",
      "Working with batch:  760\n",
      "Working with batch:  761\n",
      "Working with batch:  762\n",
      "Working with batch:  763\n",
      "Working with batch:  764\n",
      "Working with batch:  765\n",
      "Working with batch:  766\n",
      "Working with batch:  767\n",
      "Working with batch:  768\n",
      "Working with batch:  769\n",
      "Working with batch:  770\n",
      "Working with batch:  771\n",
      "Working with batch:  772\n",
      "Working with batch:  773\n",
      "Working with batch:  774\n",
      "Working with batch:  775\n",
      "Working with batch:  776\n",
      "Working with batch:  777\n",
      "Working with batch:  778\n",
      "Working with batch:  779\n",
      "Working with batch:  780\n",
      "Working with batch:  781\n",
      "Working with batch:  782\n",
      "Working with batch:  783\n",
      "Working with batch:  784\n",
      "Working with batch:  785\n",
      "Working with batch:  786\n",
      "Working with batch:  787\n",
      "Working with batch:  788\n",
      "Working with batch:  789\n",
      "Working with batch:  790\n",
      "Working with batch:  791\n",
      "Working with batch:  792\n",
      "Working with batch:  793\n",
      "Working with batch:  794\n",
      "Working with batch:  795\n",
      "Working with batch:  796\n",
      "Working with batch:  797\n",
      "Working with batch:  798\n",
      "Working with batch:  799\n",
      "Working with batch:  800\n",
      "Working with batch:  801\n",
      "Working with batch:  802\n",
      "Working with batch:  803\n",
      "Working with batch:  804\n",
      "Working with batch:  805\n",
      "Working with batch:  806\n",
      "Working with batch:  807\n",
      "Working with batch:  808\n",
      "Working with batch:  809\n",
      "Working with batch:  810\n",
      "Working with batch:  811\n",
      "Working with batch:  812\n",
      "Working with batch:  813\n",
      "Working with batch:  814\n",
      "Working with batch:  815\n",
      "Working with batch:  816\n",
      "Working with batch:  817\n",
      "Working with batch:  818\n",
      "Working with batch:  819\n",
      "Working with batch:  820\n",
      "Working with batch:  821\n",
      "Working with batch:  822\n",
      "Working with batch:  823\n",
      "Working with batch:  824\n",
      "Working with batch:  825\n",
      "Working with batch:  826\n",
      "Working with batch:  827\n",
      "Working with batch:  828\n",
      "Working with batch:  829\n",
      "Working with batch:  830\n",
      "Working with batch:  831\n",
      "Working with batch:  832\n",
      "Working with batch:  833\n",
      "Working with batch:  834\n",
      "Working with batch:  835\n",
      "Working with batch:  836\n",
      "Working with batch:  837\n",
      "Working with batch:  838\n",
      "Working with batch:  839\n",
      "Working with batch:  840\n",
      "Working with batch:  841\n",
      "Working with batch:  842\n",
      "Working with batch:  843\n",
      "Working with batch:  844\n",
      "Working with batch:  845\n",
      "Working with batch:  846\n",
      "Working with batch:  847\n",
      "Working with batch:  848\n",
      "Working with batch:  849\n",
      "Working with batch:  850\n",
      "Working with batch:  851\n",
      "Working with batch:  852\n",
      "Working with batch:  853\n",
      "Working with batch:  854\n",
      "Working with batch:  855\n",
      "Working with batch:  856\n",
      "Working with batch:  857\n",
      "Working with batch:  858\n",
      "Working with batch:  859\n",
      "Working with batch:  860\n",
      "Working with batch:  861\n",
      "Working with batch:  862\n",
      "Working with batch:  863\n",
      "Working with batch:  864\n",
      "Working with batch:  865\n",
      "Working with batch:  866\n",
      "Working with batch:  867\n",
      "Working with batch:  868\n",
      "Working with batch:  869\n",
      "Working with batch:  870\n",
      "Working with batch:  871\n",
      "Working with batch:  872\n",
      "Working with batch:  873\n",
      "Working with batch:  874\n",
      "Working with batch:  875\n",
      "Working with batch:  876\n",
      "Working with batch:  877\n",
      "Working with batch:  878\n",
      "Working with batch:  879\n",
      "Working with batch:  880\n",
      "Working with batch:  881\n",
      "Working with batch:  882\n",
      "Working with batch:  883\n",
      "Working with batch:  884\n",
      "Working with batch:  885\n",
      "Working with batch:  886\n",
      "Working with batch:  887\n",
      "Working with batch:  888\n",
      "Working with batch:  889\n",
      "Working with batch:  890\n",
      "Working with batch:  891\n",
      "Working with batch:  892\n",
      "Working with batch:  893\n",
      "Working with batch:  894\n",
      "Working with batch:  895\n",
      "Working with batch:  896\n",
      "Working with batch:  897\n",
      "Working with batch:  898\n",
      "Working with batch:  899\n",
      "Working with batch:  900\n",
      "Working with batch:  901\n",
      "Working with batch:  902\n",
      "Working with batch:  903\n",
      "Working with batch:  904\n",
      "Working with batch:  905\n",
      "Working with batch:  906\n",
      "Working with batch:  907\n",
      "Working with batch:  908\n",
      "Working with batch:  909\n",
      "Working with batch:  910\n",
      "Working with batch:  911\n",
      "Working with batch:  912\n",
      "Working with batch:  913\n",
      "Working with batch:  914\n",
      "Working with batch:  915\n",
      "Working with batch:  916\n",
      "Working with batch:  917\n",
      "Working with batch:  918\n",
      "Working with batch:  919\n",
      "Working with batch:  920\n",
      "Working with batch:  921\n",
      "Working with batch:  922\n",
      "Working with batch:  923\n",
      "Working with batch:  924\n",
      "Working with batch:  925\n",
      "Working with batch:  926\n",
      "Working with batch:  927\n",
      "Working with batch:  928\n",
      "Working with batch:  929\n",
      "Working with batch:  930\n",
      "Working with batch:  931\n",
      "Working with batch:  932\n",
      "Working with batch:  933\n",
      "Working with batch:  934\n",
      "Working with batch:  935\n",
      "Working with batch:  936\n",
      "Working with batch:  937\n",
      "Working with batch:  938\n",
      "Working with batch:  939\n",
      "Working with batch:  940\n",
      "Working with batch:  941\n",
      "Working with batch:  942\n",
      "Working with batch:  943\n",
      "Working with batch:  944\n",
      "Working with batch:  945\n",
      "Working with batch:  946\n",
      "Working with batch:  947\n",
      "Working with batch:  948\n",
      "Working with batch:  949\n",
      "Working with batch:  950\n",
      "Working with batch:  951\n",
      "Working with batch:  952\n",
      "Working with batch:  953\n",
      "Working with batch:  954\n",
      "Working with batch:  955\n",
      "Working with batch:  956\n",
      "Working with batch:  957\n",
      "Working with batch:  958\n",
      "Working with batch:  959\n",
      "Working with batch:  960\n",
      "Working with batch:  961\n",
      "Working with batch:  962\n",
      "Working with batch:  963\n",
      "Working with batch:  964\n",
      "Working with batch:  965\n",
      "Working with batch:  966\n",
      "Working with batch:  967\n",
      "Working with batch:  968\n",
      "Working with batch:  969\n",
      "Working with batch:  970\n",
      "Working with batch:  971\n",
      "Working with batch:  972\n",
      "Working with batch:  973\n",
      "Working with batch:  974\n",
      "Working with batch:  975\n",
      "Working with batch:  976\n",
      "Working with batch:  977\n",
      "Working with batch:  978\n",
      "Working with batch:  979\n",
      "Working with batch:  980\n",
      "Working with batch:  981\n",
      "Working with batch:  982\n",
      "Working with batch:  983\n",
      "Working with batch:  984\n",
      "Working with batch:  985\n",
      "Working with batch:  986\n",
      "Working with batch:  987\n",
      "Working with batch:  988\n",
      "Working with batch:  989\n",
      "Working with batch:  990\n",
      "Working with batch:  991\n",
      "Working with batch:  992\n",
      "Working with batch:  993\n",
      "Working with batch:  994\n",
      "Working with batch:  995\n",
      "Working with batch:  996\n",
      "Working with batch:  997\n",
      "Working with batch:  998\n",
      "Working with batch:  999\n",
      "Working with batch:  1000\n",
      "Working with batch:  1001\n",
      "Working with batch:  1002\n",
      "Working with batch:  1003\n",
      "Working with batch:  1004\n",
      "Working with batch:  1005\n",
      "Working with batch:  1006\n",
      "Working with batch:  1007\n",
      "Working with batch:  1008\n",
      "Working with batch:  1009\n",
      "Working with batch:  1010\n",
      "Working with batch:  1011\n",
      "Working with batch:  1012\n",
      "Working with batch:  1013\n",
      "Working with batch:  1014\n",
      "Working with batch:  1015\n",
      "Working with batch:  1016\n",
      "Working with batch:  1017\n",
      "Working with batch:  1018\n",
      "Working with batch:  1019\n",
      "Working with batch:  1020\n",
      "Working with batch:  1021\n",
      "Working with batch:  1022\n",
      "Working with batch:  1023\n",
      "Working with batch:  1024\n",
      "Working with batch:  1025\n",
      "Working with batch:  1026\n",
      "Working with batch:  1027\n",
      "Working with batch:  1028\n",
      "Working with batch:  1029\n",
      "Working with batch:  1030\n",
      "Working with batch:  1031\n",
      "Working with batch:  1032\n",
      "Working with batch:  1033\n",
      "Working with batch:  1034\n",
      "Working with batch:  1035\n",
      "Working with batch:  1036\n",
      "Working with batch:  1037\n",
      "Working with batch:  1038\n",
      "Working with batch:  1039\n",
      "Working with batch:  1040\n",
      "Working with batch:  1041\n",
      "Working with batch:  1042\n",
      "Working with batch:  1043\n",
      "Working with batch:  1044\n",
      "Working with batch:  1045\n",
      "Working with batch:  1046\n",
      "Working with batch:  1047\n",
      "Working with batch:  1048\n",
      "Working with batch:  1049\n",
      "Working with batch:  1050\n",
      "Working with batch:  1051\n",
      "Working with batch:  1052\n",
      "Working with batch:  1053\n",
      "Working with batch:  1054\n",
      "Working with batch:  1055\n",
      "Working with batch:  1056\n",
      "Working with batch:  1057\n",
      "Working with batch:  1058\n",
      "Working with batch:  1059\n",
      "Working with batch:  1060\n",
      "Working with batch:  1061\n",
      "Working with batch:  1062\n",
      "Working with batch:  1063\n",
      "Working with batch:  1064\n",
      "Working with batch:  1065\n",
      "Working with batch:  1066\n",
      "Working with batch:  1067\n",
      "Working with batch:  1068\n",
      "Working with batch:  1069\n",
      "Working with batch:  1070\n",
      "Working with batch:  1071\n",
      "Working with batch:  1072\n",
      "Working with batch:  1073\n",
      "Working with batch:  1074\n",
      "Working with batch:  1075\n",
      "Working with batch:  1076\n",
      "Working with batch:  1077\n",
      "Working with batch:  1078\n",
      "Working with batch:  1079\n",
      "Working with batch:  1080\n",
      "Working with batch:  1081\n",
      "Working with batch:  1082\n",
      "Working with batch:  1083\n",
      "Working with batch:  1084\n",
      "Working with batch:  1085\n",
      "Working with batch:  1086\n",
      "Working with batch:  1087\n",
      "Working with batch:  1088\n",
      "Working with batch:  1089\n",
      "Working with batch:  1090\n",
      "Working with batch:  1091\n",
      "Working with batch:  1092\n",
      "Working with batch:  1093\n",
      "Working with batch:  1094\n",
      "Working with batch:  1095\n",
      "Working with batch:  1096\n",
      "Working with batch:  1097\n",
      "Working with batch:  1098\n",
      "Working with batch:  1099\n",
      "Working with batch:  1100\n",
      "Working with batch:  1101\n",
      "Working with batch:  1102\n",
      "Working with batch:  1103\n",
      "Working with batch:  1104\n",
      "Working with batch:  1105\n",
      "Working with batch:  1106\n",
      "Working with batch:  1107\n",
      "Working with batch:  1108\n",
      "Working with batch:  1109\n",
      "Working with batch:  1110\n",
      "Working with batch:  1111\n",
      "Working with batch:  1112\n",
      "Working with batch:  1113\n",
      "Working with batch:  1114\n",
      "Working with batch:  1115\n",
      "Working with batch:  1116\n",
      "Working with batch:  1117\n",
      "Working with batch:  1118\n",
      "Working with batch:  1119\n",
      "Working with batch:  1120\n",
      "Working with batch:  1121\n",
      "Working with batch:  1122\n",
      "Working with batch:  1123\n",
      "Working with batch:  1124\n",
      "Working with batch:  1125\n",
      "Working with batch:  1126\n",
      "Working with batch:  1127\n",
      "Working with batch:  1128\n",
      "Working with batch:  1129\n",
      "Working with batch:  1130\n",
      "Working with batch:  1131\n",
      "Working with batch:  1132\n",
      "Working with batch:  1133\n",
      "Working with batch:  1134\n",
      "Working with batch:  1135\n",
      "Working with batch:  1136\n",
      "Working with batch:  1137\n",
      "Working with batch:  1138\n",
      "Working with batch:  1139\n",
      "Working with batch:  1140\n",
      "Working with batch:  1141\n",
      "Working with batch:  1142\n",
      "Working with batch:  1143\n",
      "Working with batch:  1144\n",
      "Working with batch:  1145\n",
      "Working with batch:  1146\n",
      "Working with batch:  1147\n",
      "Working with batch:  1148\n",
      "Working with batch:  1149\n",
      "Working with batch:  1150\n",
      "Working with batch:  1151\n",
      "Working with batch:  1152\n",
      "Working with batch:  1153\n",
      "Working with batch:  1154\n",
      "Working with batch:  1155\n",
      "Working with batch:  1156\n",
      "Working with batch:  1157\n",
      "Working with batch:  1158\n",
      "Working with batch:  1159\n",
      "Working with batch:  1160\n",
      "Working with batch:  1161\n",
      "Working with batch:  1162\n",
      "Working with batch:  1163\n",
      "Working with batch:  1164\n",
      "Working with batch:  1165\n",
      "Working with batch:  1166\n",
      "Working with batch:  1167\n",
      "Working with batch:  1168\n",
      "Working with batch:  1169\n",
      "Working with batch:  1170\n",
      "Working with batch:  1171\n",
      "Working with batch:  1172\n",
      "Working with batch:  1173\n",
      "Working with batch:  1174\n",
      "Working with batch:  1175\n",
      "Working with batch:  1176\n",
      "Working with batch:  1177\n",
      "Working with batch:  1178\n",
      "Working with batch:  1179\n",
      "Working with batch:  1180\n",
      "Working with batch:  1181\n",
      "Working with batch:  1182\n",
      "Working with batch:  1183\n",
      "Working with batch:  1184\n",
      "Working with batch:  1185\n",
      "Working with batch:  1186\n",
      "Working with batch:  1187\n",
      "Working with batch:  1188\n",
      "Working with batch:  1189\n",
      "Working with batch:  1190\n",
      "Working with batch:  1191\n",
      "Working with batch:  1192\n",
      "Working with batch:  1193\n",
      "Working with batch:  1194\n",
      "Working with batch:  1195\n",
      "Working with batch:  1196\n",
      "Working with batch:  1197\n",
      "Working with batch:  1198\n",
      "Working with batch:  1199\n",
      "Working with batch:  1200\n",
      "Working with batch:  1201\n",
      "Working with batch:  1202\n",
      "Working with batch:  1203\n",
      "Working with batch:  1204\n",
      "Working with batch:  1205\n",
      "Working with batch:  1206\n",
      "Working with batch:  1207\n",
      "Working with batch:  1208\n",
      "Working with batch:  1209\n",
      "Working with batch:  1210\n",
      "Working with batch:  1211\n",
      "Working with batch:  1212\n",
      "Working with batch:  1213\n",
      "Working with batch:  1214\n",
      "Working with batch:  1215\n",
      "Working with batch:  1216\n",
      "Working with batch:  1217\n",
      "Working with batch:  1218\n",
      "Working with batch:  1219\n",
      "Working with batch:  1220\n",
      "Working with batch:  1221\n",
      "Working with batch:  1222\n",
      "Working with batch:  1223\n",
      "Working with batch:  1224\n",
      "Working with batch:  1225\n",
      "Working with batch:  1226\n",
      "Working with batch:  1227\n",
      "Working with batch:  1228\n",
      "Working with batch:  1229\n",
      "Working with batch:  1230\n",
      "Working with batch:  1231\n",
      "Working with batch:  1232\n",
      "Working with batch:  1233\n",
      "Working with batch:  1234\n",
      "Working with batch:  1235\n",
      "Working with batch:  1236\n",
      "Working with batch:  1237\n",
      "Working with batch:  1238\n",
      "Working with batch:  1239\n",
      "Working with batch:  1240\n",
      "Working with batch:  1241\n",
      "Working with batch:  1242\n",
      "Working with batch:  1243\n",
      "Working with batch:  1244\n",
      "Working with batch:  1245\n",
      "Working with batch:  1246\n",
      "Working with batch:  1247\n",
      "Working with batch:  1248\n",
      "Working with batch:  1249\n",
      "Working with batch:  1250\n",
      "Working with batch:  1251\n",
      "Working with batch:  1252\n",
      "Working with batch:  1253\n",
      "Working with batch:  1254\n",
      "Working with batch:  1255\n",
      "Working with batch:  1256\n",
      "Working with batch:  1257\n",
      "Working with batch:  1258\n",
      "Working with batch:  1259\n",
      "Working with batch:  1260\n",
      "Working with batch:  1261\n",
      "Working with batch:  1262\n",
      "Working with batch:  1263\n",
      "Working with batch:  1264\n",
      "Working with batch:  1265\n",
      "Working with batch:  1266\n",
      "Working with batch:  1267\n",
      "Working with batch:  1268\n",
      "Working with batch:  1269\n",
      "Working with batch:  1270\n",
      "Working with batch:  1271\n",
      "Working with batch:  1272\n",
      "Working with batch:  1273\n",
      "Working with batch:  1274\n",
      "Working with batch:  1275\n",
      "Working with batch:  1276\n",
      "Working with batch:  1277\n",
      "Working with batch:  1278\n",
      "Working with batch:  1279\n",
      "Working with batch:  1280\n",
      "Working with batch:  1281\n",
      "Working with batch:  1282\n",
      "Working with batch:  1283\n",
      "Working with batch:  1284\n",
      "Working with batch:  1285\n",
      "Working with batch:  1286\n",
      "Working with batch:  1287\n",
      "Working with batch:  1288\n",
      "Working with batch:  1289\n",
      "Working with batch:  1290\n",
      "Working with batch:  1291\n",
      "Working with batch:  1292\n",
      "Working with batch:  1293\n",
      "Working with batch:  1294\n",
      "Working with batch:  1295\n",
      "Working with batch:  1296\n",
      "Working with batch:  1297\n",
      "Working with batch:  1298\n",
      "Working with batch:  1299\n",
      "Working with batch:  1300\n",
      "Working with batch:  1301\n",
      "Working with batch:  1302\n",
      "Working with batch:  1303\n",
      "Working with batch:  1304\n",
      "Working with batch:  1305\n",
      "Working with batch:  1306\n",
      "Working with batch:  1307\n",
      "Working with batch:  1308\n",
      "Working with batch:  1309\n",
      "Working with batch:  1310\n",
      "Working with batch:  1311\n",
      "Working with batch:  1312\n",
      "Working with batch:  1313\n",
      "Working with batch:  1314\n",
      "Working with batch:  1315\n",
      "Working with batch:  1316\n",
      "Working with batch:  1317\n",
      "Working with batch:  1318\n",
      "Working with batch:  1319\n",
      "Working with batch:  1320\n",
      "Working with batch:  1321\n",
      "Working with batch:  1322\n",
      "Working with batch:  1323\n",
      "Working with batch:  1324\n",
      "Working with batch:  1325\n",
      "Working with batch:  1326\n",
      "Working with batch:  1327\n",
      "Working with batch:  1328\n",
      "Working with batch:  1329\n",
      "Working with batch:  1330\n",
      "Working with batch:  1331\n",
      "Working with batch:  1332\n",
      "Working with batch:  1333\n",
      "Working with batch:  1334\n",
      "Working with batch:  1335\n",
      "Working with batch:  1336\n",
      "Working with batch:  1337\n",
      "Working with batch:  1338\n",
      "Working with batch:  1339\n",
      "Working with batch:  1340\n",
      "Working with batch:  1341\n",
      "Working with batch:  1342\n",
      "Working with batch:  1343\n",
      "Working with batch:  1344\n",
      "Working with batch:  1345\n",
      "Working with batch:  1346\n",
      "Working with batch:  1347\n",
      "Working with batch:  1348\n",
      "Working with batch:  1349\n",
      "Working with batch:  1350\n",
      "Working with batch:  1351\n",
      "Working with batch:  1352\n",
      "Working with batch:  1353\n",
      "Working with batch:  1354\n",
      "Working with batch:  1355\n",
      "Working with batch:  1356\n",
      "Working with batch:  1357\n",
      "Working with batch:  1358\n",
      "Working with batch:  1359\n",
      "Working with batch:  1360\n",
      "Working with batch:  1361\n",
      "Working with batch:  1362\n",
      "Working with batch:  1363\n",
      "Working with batch:  1364\n",
      "Working with batch:  1365\n",
      "Working with batch:  1366\n",
      "Working with batch:  1367\n",
      "Working with batch:  1368\n",
      "Working with batch:  1369\n",
      "Working with batch:  1370\n",
      "Working with batch:  1371\n",
      "Working with batch:  1372\n",
      "Working with batch:  1373\n",
      "Working with batch:  1374\n",
      "Working with batch:  1375\n",
      "Working with batch:  1376\n",
      "Working with batch:  1377\n",
      "Working with batch:  1378\n",
      "Working with batch:  1379\n"
     ]
    }
   ],
   "source": [
    "filepaths = dfFoldTraining_1['filenames']\n",
    "\n",
    "n_files = len(filepaths)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "num_processes = 4\n",
    "\n",
    "results = []\n",
    "\n",
    "i=0;\n",
    "with tqdm(total=n_files, desc=\"Extract Gabor features\") as pbar:\n",
    "\n",
    "    with Parallel(n_jobs=num_processes) as parallel:\n",
    "\n",
    "        for batch in chunked(image_generator(filepaths), batch_size):\n",
    "            \n",
    "            i=i+1\n",
    "            print('Working with batch: ',i)\n",
    "\n",
    "            batch_results = parallel(\n",
    "                delayed(extract_texture_features)(img) for img in batch)\n",
    "            \n",
    "            results.extend(batch_results)\n",
    "\n",
    "            del batch_results\n",
    "            gc.collect()\n",
    "\n",
    "            pbar.update(len(batch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'results' (list)\n"
     ]
    }
   ],
   "source": [
    "%store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tables\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'd rather comment than offer this as an actual answer, but I need more reputation to comment.)\n",
    "\n",
    "You can store most data-like variables in a systematic way. What I usually do is store all dataframes, arrays, etc. in pandas.HDFStore. At the beginning of the notebook, declare\n",
    "\n",
    "backup = pd.HDFStore('backup.h5')\n",
    "and then store any new variables as you produce them\n",
    "\n",
    "backup['var1'] = var1\n",
    "At the end, probably a good idea to do\n",
    "\n",
    "backup.close()\n",
    "before turning off the server. The next time you want to continue with the notebook:\n",
    "\n",
    "backup = pd.HDFStore('backup.h5')\n",
    "var1 = backup['var1']\n",
    "Truth be told, I'd prefer built-in functionality in ipython notebook, too. You can't save everything this way (e.g. objects, connections), and it's hard to keep the notebook organized with so much boilerplate codes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image_processing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
